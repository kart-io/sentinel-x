package tools

import (
	"context"
	"log"
	"regexp"
	"sync"
	"sync/atomic"
	"time"

	agentErrors "github.com/kart-io/goagent/errors"
	"github.com/kart-io/goagent/interfaces"
)

// ShardedToolCache 分片工具缓存
//
// 使用分片策略降低锁竞争的高性能缓存实现
type ShardedToolCache struct {
	shards       []*cacheShard
	shardCount   uint32
	cleanupDone  sync.WaitGroup
	ctx          context.Context
	cancel       context.CancelFunc
	closed       atomic.Int32
	stats        *CacheStats
	dependencies map[string][]string
	depMu        sync.RWMutex
	config       ShardedCacheConfig // 存储配置

	// 自动调优相关
	lastTuneTime time.Time
	tuneMetrics  *tuneMetrics
}

// tuneMetrics 自动调优指标
type tuneMetrics struct {
	mu            sync.RWMutex
	avgHitRate    float64
	avgLoadFactor float64
	qpsHistory    []float64
}

// cacheShard 单个缓存分片
type cacheShard struct {
	mu    sync.RWMutex
	cache map[string]*cacheEntry

	// 自定义 LRU 双向链表头尾指针（零分配优化）
	head *cacheEntry
	tail *cacheEntry
	size int // 当前链表长度

	capacity int
}

// ShardedCacheConfig 分片缓存配置
type ShardedCacheConfig struct {
	// ShardCount 分片数量（建议为 2 的幂，默认 32）
	ShardCount uint32

	// Capacity 总容量（每个分片的容量 = Capacity / ShardCount）
	Capacity int

	// DefaultTTL 默认 TTL
	DefaultTTL time.Duration

	// CleanupInterval 清理间隔
	CleanupInterval time.Duration

	// EvictionPolicy 淘汰策略
	EvictionPolicy EvictionPolicy

	// CleanupStrategy 清理策略
	CleanupStrategy CleanupStrategy

	// LoadBalancing 负载均衡策略
	LoadBalancing LoadBalancingStrategy

	// AutoTuning 自动调优
	AutoTuning bool

	// MetricsEnabled 是否启用指标收集
	MetricsEnabled bool

	// MaxConcurrency 每个分片的最大并发数
	MaxConcurrency int

	// WarmupEntries 预热条目
	WarmupEntries map[string]*interfaces.ToolOutput

	// CompressionThreshold 压缩阈值（字节）
	CompressionThreshold int

	// MaxEntrySize 单个条目最大大小（字节）
	MaxEntrySize int

	// MemoryLimit 内存限制（字节）
	MemoryLimit int64

	// WorkloadType 工作负载类型
	WorkloadType WorkloadType
}

// NewShardedToolCache 创建分片工具缓存（使用配置结构体）
func NewShardedToolCache(config ShardedCacheConfig) *ShardedToolCache {
	// 应用默认值
	if config.ShardCount <= 0 || (config.ShardCount&(config.ShardCount-1)) != 0 {
		config.ShardCount = 32
	}
	if config.Capacity <= 0 {
		config.Capacity = 10000
	}
	if config.DefaultTTL <= 0 {
		config.DefaultTTL = 5 * time.Minute
	}
	if config.CleanupInterval <= 0 {
		config.CleanupInterval = 1 * time.Minute
	}

	return newShardedToolCacheWithConfig(config)
}

// NewShardedToolCacheWithOptions 使用选项模式创建分片工具缓存
func NewShardedToolCacheWithOptions(opts ...ShardedCacheOption) *ShardedToolCache {
	// 使用默认配置
	config := DefaultShardedCacheConfig()

	// 应用所有选项
	for _, opt := range opts {
		opt(&config)
	}

	return newShardedToolCacheWithConfig(config)
}

// NewHighPerformanceCache 创建高性能缓存配置
//
// 适用于内存充足、追求极致性能的场景
// 特点：
// - 更多分片 (64)
// - 更大容量 (100,000)
// - 激进的预取和保留策略
func NewHighPerformanceCache() *ShardedToolCache {
	return NewShardedToolCache(ShardedCacheConfig{
		ShardCount:      64,
		Capacity:        100000,
		DefaultTTL:      10 * time.Minute,
		CleanupInterval: 30 * time.Second,
		AutoTuning:      true,
		MetricsEnabled:  true,
	})
}

// NewLowMemoryCache 创建低内存缓存配置
//
// 适用于资源受限环境
// 特点：
// - 较少分片 (8)
// - 较小容量 (1,000)
// - 激进的清理策略
func NewLowMemoryCache() *ShardedToolCache {
	return NewShardedToolCache(ShardedCacheConfig{
		ShardCount:           8,
		Capacity:             1000,
		DefaultTTL:           2 * time.Minute,
		CleanupInterval:      1 * time.Minute,
		AutoTuning:           false,
		MetricsEnabled:       false,
		CompressionThreshold: 1024, // 启用压缩
	})
}

// newShardedToolCacheWithConfig 内部创建函数
func newShardedToolCacheWithConfig(config ShardedCacheConfig) *ShardedToolCache {
	ctx, cancel := context.WithCancel(context.Background())
	shardCapacity := config.Capacity / int(config.ShardCount)
	if shardCapacity < 1 {
		shardCapacity = 1
	}

	cache := &ShardedToolCache{
		shards:       make([]*cacheShard, config.ShardCount),
		shardCount:   config.ShardCount,
		ctx:          ctx,
		cancel:       cancel,
		stats:        &CacheStats{},
		dependencies: make(map[string][]string),
		config:       config,
	}

	// 初始化分片
	for i := uint32(0); i < config.ShardCount; i++ {
		cache.shards[i] = &cacheShard{
			cache:    make(map[string]*cacheEntry),
			capacity: shardCapacity,
			head:     nil,
			tail:     nil,
			size:     0,
		}
	}

	cache.closed.Store(0)

	// 应用预热条目
	if config.WarmupEntries != nil {
		for key, output := range config.WarmupEntries {
			_ = cache.Set(ctx, key, output, config.DefaultTTL)
		}
	}

	// 根据清理策略启动清理
	switch config.CleanupStrategy {
	case PeriodicCleanup, HybridCleanup:
		if config.CleanupInterval > 0 {
			cache.cleanupDone.Add(1)
			go cache.cleanupExpired(config.CleanupInterval, config.DefaultTTL)
		}
	case AdaptiveCleanup:
		cache.cleanupDone.Add(1)
		go cache.adaptiveCleanup()
	}

	// 启动自动调优
	if config.AutoTuning {
		cache.cleanupDone.Add(1)
		go cache.autoTune()
	}

	return cache
}

// FNV-1a hash constants
const (
	offset32 = 2166136261
	prime32  = 16777619
)

// hashString 计算字符串哈希值（零分配内联优化）
// 替代 fnv.New32a().Write([]byte(s))，避免 slice 分配
//
//go:inline
func hashString(s string) uint32 {
	hash := uint32(offset32)
	for i := 0; i < len(s); i++ {
		hash ^= uint32(s[i])
		hash *= prime32
	}
	return hash
}

// getShard 根据键获取对应的分片（零分配优化）
func (c *ShardedToolCache) getShard(key string) *cacheShard {
	return c.shards[hashString(key)&(c.shardCount-1)]
}

// Get 获取缓存结果
func (c *ShardedToolCache) Get(ctx context.Context, key string) (*interfaces.ToolOutput, bool) {
	shard := c.getShard(key)

	shard.mu.Lock()
	defer shard.mu.Unlock()

	entry, exists := shard.cache[key]
	if !exists {
		c.stats.recordMiss()
		return nil, false
	}

	// 检查是否过期
	if time.Now().After(entry.expireTime) {
		c.removeEntryFromShard(shard, entry)
		c.stats.recordMiss()
		return nil, false
	}

	// 移到 LRU 链表头部（自定义链表操作）
	c.moveToHead(shard, entry)
	c.stats.recordHit()

	return entry.output, true
}

// Set 设置缓存结果
func (c *ShardedToolCache) Set(ctx context.Context, key string, output *interfaces.ToolOutput, ttl time.Duration) error {
	shard := c.getShard(key)
	toolName := extractToolNameFromKey(key)

	shard.mu.Lock()
	defer shard.mu.Unlock()

	// 如果已存在，更新
	if entry, exists := shard.cache[key]; exists {
		entry.output = output
		entry.expireTime = time.Now().Add(ttl)
		entry.toolName = toolName
		c.moveToHead(shard, entry)
		return nil
	}

	// 检查容量，如果满了则淘汰最久未使用的（尾部）
	if shard.size >= shard.capacity {
		c.evictOldestFromShard(shard)
	}

	// 添加新条目
	entry := &cacheEntry{
		key:        key,
		toolName:   toolName,
		output:     output,
		expireTime: time.Now().Add(ttl),
		version:    0,
	}

	c.addToHead(shard, entry)
	shard.cache[key] = entry

	return nil
}

// Delete 删除缓存
func (c *ShardedToolCache) Delete(ctx context.Context, key string) error {
	shard := c.getShard(key)

	shard.mu.Lock()
	defer shard.mu.Unlock()

	if entry, exists := shard.cache[key]; exists {
		c.removeEntryFromShard(shard, entry)
	}

	return nil
}

// Clear 清空所有缓存
func (c *ShardedToolCache) Clear() error {
	for _, shard := range c.shards {
		shard.mu.Lock()
		shard.cache = make(map[string]*cacheEntry)
		shard.head = nil
		shard.tail = nil
		shard.size = 0
		shard.mu.Unlock()
	}
	return nil
}

// Size 返回缓存大小
func (c *ShardedToolCache) Size() int {
	total := 0
	for _, shard := range c.shards {
		shard.mu.RLock()
		total += len(shard.cache)
		shard.mu.RUnlock()
	}
	return total
}

// InvalidateByPattern 根据正则表达式模式失效缓存
func (c *ShardedToolCache) InvalidateByPattern(ctx context.Context, pattern string) (int, error) {
	re, err := regexp.Compile(pattern)
	if err != nil {
		return 0, agentErrors.Wrap(err, agentErrors.CodeInvalidInput, "invalid regex pattern").
			WithComponent("sharded_tool_cache").
			WithOperation("invalidate_by_pattern")
	}

	totalCount := 0
	affectedTools := make(map[string]struct{})

	// 遍历所有分片
	for _, shard := range c.shards {
		shard.mu.Lock()
		keysToRemove := make([]string, 0)

		for key, entry := range shard.cache {
			if re.MatchString(key) {
				keysToRemove = append(keysToRemove, key)
				if entry.toolName != "" {
					affectedTools[entry.toolName] = struct{}{}
				}
			}
		}

		for _, key := range keysToRemove {
			if entry, exists := shard.cache[key]; exists {
				c.removeEntryFromShard(shard, entry)
				totalCount++
			}
		}
		shard.mu.Unlock()
	}

	// 级联失效依赖的工具，使用 visited 集合防止循环依赖
	visited := make(map[string]struct{})
	for toolName := range affectedTools {
		visited[toolName] = struct{}{}
	}

	for toolName := range affectedTools {
		count := c.invalidateDependentsRecursive(toolName, visited)
		totalCount += count
	}

	c.stats.recordInvalidation(int64(totalCount))
	return totalCount, nil
}

// InvalidateByTool 根据工具名称失效缓存
func (c *ShardedToolCache) InvalidateByTool(ctx context.Context, toolName string) (int, error) {
	totalCount := 0

	// 遍历所有分片
	for _, shard := range c.shards {
		shard.mu.Lock()
		keysToRemove := make([]string, 0)

		for key, entry := range shard.cache {
			if entry.toolName == toolName {
				keysToRemove = append(keysToRemove, key)
			}
		}

		for _, key := range keysToRemove {
			if entry, exists := shard.cache[key]; exists {
				c.removeEntryFromShard(shard, entry)
				totalCount++
			}
		}
		shard.mu.Unlock()
	}

	// 级联失效依赖的工具，使用 visited 集合防止循环依赖
	visited := make(map[string]struct{})
	visited[toolName] = struct{}{}
	dependentCount := c.invalidateDependentsRecursive(toolName, visited)
	totalCount += dependentCount

	c.stats.recordInvalidation(int64(totalCount))
	return totalCount, nil
}

// invalidateDependentsRecursive 失效依赖指定工具的所有工具（带循环检测）
func (c *ShardedToolCache) invalidateDependentsRecursive(toolName string, visited map[string]struct{}) int {
	c.depMu.RLock()
	dependents, exists := c.dependencies[toolName]
	c.depMu.RUnlock()

	if !exists || len(dependents) == 0 {
		return 0
	}

	totalCount := 0
	for _, dependent := range dependents {
		// 检测循环依赖：如果该工具已经被访问过，跳过以避免无限递归
		if _, seen := visited[dependent]; seen {
			continue
		}
		visited[dependent] = struct{}{}

		// 遍历所有分片删除依赖工具
		for _, shard := range c.shards {
			shard.mu.Lock()
			keysToRemove := make([]string, 0)

			for key, entry := range shard.cache {
				if entry.toolName == dependent {
					keysToRemove = append(keysToRemove, key)
				}
			}

			for _, key := range keysToRemove {
				if entry, exists := shard.cache[key]; exists {
					c.removeEntryFromShard(shard, entry)
					totalCount++
				}
			}
			shard.mu.Unlock()
		}

		// 递归失效，传递 visited 集合
		totalCount += c.invalidateDependentsRecursive(dependent, visited)
	}

	return totalCount
}

// AddDependency 添加工具依赖关系
func (c *ShardedToolCache) AddDependency(dependentTool, dependsOnTool string) {
	c.depMu.Lock()
	defer c.depMu.Unlock()

	if c.dependencies[dependsOnTool] == nil {
		c.dependencies[dependsOnTool] = make([]string, 0)
	}

	for _, dep := range c.dependencies[dependsOnTool] {
		if dep == dependentTool {
			return
		}
	}

	c.dependencies[dependsOnTool] = append(c.dependencies[dependsOnTool], dependentTool)
}

// RemoveDependency 移除工具依赖关系
func (c *ShardedToolCache) RemoveDependency(dependentTool, dependsOnTool string) {
	c.depMu.Lock()
	defer c.depMu.Unlock()

	deps, exists := c.dependencies[dependsOnTool]
	if !exists {
		return
	}

	for i, dep := range deps {
		if dep == dependentTool {
			c.dependencies[dependsOnTool] = append(deps[:i], deps[i+1:]...)
			return
		}
	}
}

// GetStats 获取统计信息
func (c *ShardedToolCache) GetStats() CacheStats {
	return CacheStats{
		Hits:          *copyAtomicInt64(&c.stats.Hits),
		Misses:        *copyAtomicInt64(&c.stats.Misses),
		Evicts:        *copyAtomicInt64(&c.stats.Evicts),
		Invalidations: *copyAtomicInt64(&c.stats.Invalidations),
	}
}

// GetStatsValues 获取统计信息的数值
func (c *ShardedToolCache) GetStatsValues() (hits, misses, evicts, invalidations int64) {
	return c.stats.Hits.Load(), c.stats.Misses.Load(),
		c.stats.Evicts.Load(), c.stats.Invalidations.Load()
}

// GetVersion 获取当前缓存版本号（分片缓存不使用版本号）
func (c *ShardedToolCache) GetVersion() int64 {
	return 0
}

// Close 关闭缓存，清理资源
func (c *ShardedToolCache) Close() {
	if !c.closed.CompareAndSwap(0, 1) {
		return
	}

	c.cancel()
	c.cleanupDone.Wait()
}

// --- 自定义 LRU 链表操作辅助函数（零分配优化）---

// addToHead 将节点添加到头部
func (c *ShardedToolCache) addToHead(shard *cacheShard, entry *cacheEntry) {
	if shard.head == nil {
		// 空链表
		shard.head = entry
		shard.tail = entry
		entry.prev = nil
		entry.next = nil
	} else {
		// 插入到头部
		entry.next = shard.head
		entry.prev = nil
		shard.head.prev = entry
		shard.head = entry
	}
	shard.size++
}

// moveToHead 将现有节点移动到头部（LRU 访问更新）
func (c *ShardedToolCache) moveToHead(shard *cacheShard, entry *cacheEntry) {
	if shard.head == entry {
		return // 已经在头部
	}

	// 从当前位置移除
	if entry.prev != nil {
		entry.prev.next = entry.next
	}
	if entry.next != nil {
		entry.next.prev = entry.prev
	}
	if shard.tail == entry {
		shard.tail = entry.prev
	}

	// 添加到头部
	entry.next = shard.head
	entry.prev = nil
	if shard.head != nil {
		shard.head.prev = entry
	}
	shard.head = entry
	if shard.tail == nil {
		shard.tail = entry
	}
}

// removeEntryFromShard 从分片中移除条目（内部方法，不加锁）
func (c *ShardedToolCache) removeEntryFromShard(shard *cacheShard, entry *cacheEntry) {
	// 从双向链表移除
	if entry.prev != nil {
		entry.prev.next = entry.next
	} else {
		shard.head = entry.next
	}

	if entry.next != nil {
		entry.next.prev = entry.prev
	} else {
		shard.tail = entry.prev
	}

	entry.prev = nil
	entry.next = nil

	delete(shard.cache, entry.key)
	shard.size--
}

// evictOldestFromShard 从分片中淘汰最久未使用的条目（尾部）
func (c *ShardedToolCache) evictOldestFromShard(shard *cacheShard) {
	if shard.tail != nil {
		c.removeEntryFromShard(shard, shard.tail)
		c.stats.recordEvict()
	}
}

// cleanupExpired 清理过期条目
func (c *ShardedToolCache) cleanupExpired(interval, defaultTTL time.Duration) {
	defer c.cleanupDone.Done()
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-c.ctx.Done():
			return
		case <-ticker.C:
			c.performCleanup()
		}
	}
}

// performCleanup 执行一次清理操作
func (c *ShardedToolCache) performCleanup() {
	now := time.Now()

	// 并发清理每个分片
	var wg sync.WaitGroup
	for _, shard := range c.shards {
		wg.Add(1)
		go func(s *cacheShard) {
			defer wg.Done()

			// 收集过期键
			s.mu.RLock()
			expiredKeys := make([]string, 0)
			for key, entry := range s.cache {
				if now.After(entry.expireTime) {
					expiredKeys = append(expiredKeys, key)
				}
			}
			s.mu.RUnlock()

			// 删除过期条目
			if len(expiredKeys) > 0 {
				s.mu.Lock()
				for _, key := range expiredKeys {
					if entry, exists := s.cache[key]; exists && now.After(entry.expireTime) {
						c.removeEntryFromShard(s, entry)
					}
				}
				s.mu.Unlock()
			}
		}(shard)
	}
	wg.Wait()
}

// CreateShardedCache 创建分片缓存的辅助函数
func CreateShardedCache() ToolCache {
	return NewShardedToolCache(ShardedCacheConfig{
		ShardCount:      32,    // 32 个分片
		Capacity:        10000, // 总容量 10000
		DefaultTTL:      5 * time.Minute,
		CleanupInterval: 1 * time.Minute,
	})
}

// BenchmarkCompareShardedVsNormal 基准测试对比分片缓存和普通缓存
func BenchmarkCompareShardedVsNormal() {
	// 此函数可用于性能测试对比
	// 使用方法：go test -bench=BenchmarkCompare
	normalCache := NewMemoryToolCache(MemoryCacheConfig{
		Capacity:        10000,
		DefaultTTL:      5 * time.Minute,
		CleanupInterval: 1 * time.Minute,
	})
	defer normalCache.Close()

	shardedCache := NewShardedToolCache(ShardedCacheConfig{
		ShardCount:      32,
		Capacity:        10000,
		DefaultTTL:      5 * time.Minute,
		CleanupInterval: 1 * time.Minute,
	})
	defer shardedCache.Close()

	// 在高并发场景下，分片缓存性能会显著优于普通缓存
	// 特别是在多核 CPU 上，分片缓存可以实现近乎线性的扩展
	log.Println("Sharded cache created for benchmarking")
}

// adaptiveCleanup 自适应清理策略
func (c *ShardedToolCache) adaptiveCleanup() {
	defer c.cleanupDone.Done()

	baseInterval := c.config.CleanupInterval
	if baseInterval <= 0 {
		baseInterval = 1 * time.Minute
	}

	currentInterval := baseInterval
	ticker := time.NewTicker(currentInterval)
	defer ticker.Stop()

	for {
		select {
		case <-c.ctx.Done():
			return
		case <-ticker.C:
			// 执行清理
			cleanedCount := c.performCleanupWithCount()

			// 根据清理的条目数量调整间隔
			loadFactor := float64(c.Size()) / float64(c.config.Capacity)

			if loadFactor > 0.9 || cleanedCount > c.config.Capacity/10 {
				// 负载高或清理了很多条目，减少间隔
				currentInterval = baseInterval / 2
			} else if loadFactor < 0.5 && cleanedCount < c.config.Capacity/100 {
				// 负载低且清理很少，增加间隔
				currentInterval = baseInterval * 2
			} else {
				currentInterval = baseInterval
			}

			// 限制间隔范围
			if currentInterval < 10*time.Second {
				currentInterval = 10 * time.Second
			} else if currentInterval > 10*time.Minute {
				currentInterval = 10 * time.Minute
			}

			// 重置ticker
			ticker.Reset(currentInterval)
		}
	}
}

// performCleanupWithCount 执行清理并返回清理的条目数
func (c *ShardedToolCache) performCleanupWithCount() int {
	now := time.Now()
	totalCleaned := 0

	// 并发清理每个分片
	var wg sync.WaitGroup
	cleanedCounts := make([]int, len(c.shards))

	for i, shard := range c.shards {
		wg.Add(1)
		go func(idx int, s *cacheShard) {
			defer wg.Done()

			// 收集过期键
			s.mu.RLock()
			expiredKeys := make([]string, 0)
			for key, entry := range s.cache {
				if now.After(entry.expireTime) {
					expiredKeys = append(expiredKeys, key)
				}
			}
			s.mu.RUnlock()

			// 删除过期条目
			if len(expiredKeys) > 0 {
				s.mu.Lock()
				for _, key := range expiredKeys {
					if entry, exists := s.cache[key]; exists && now.After(entry.expireTime) {
						c.removeEntryFromShard(s, entry)
						cleanedCounts[idx]++
					}
				}
				s.mu.Unlock()
			}
		}(i, shard)
	}
	wg.Wait()

	for _, count := range cleanedCounts {
		totalCleaned += count
	}

	return totalCleaned
}

// autoTune 自动调优
func (c *ShardedToolCache) autoTune() {
	defer c.cleanupDone.Done()

	// 初始化调优指标
	c.tuneMetrics = &tuneMetrics{
		qpsHistory: make([]float64, 0, 60), // 保留60个样本
	}

	ticker := time.NewTicker(10 * time.Second) // 每10秒检查一次
	defer ticker.Stop()

	var lastHits, lastMisses int64
	lastCheck := time.Now()

	for {
		select {
		case <-c.ctx.Done():
			return
		case <-ticker.C:
			now := time.Now()
			duration := now.Sub(lastCheck).Seconds()

			// 计算QPS
			currentHits := c.stats.Hits.Load()
			currentMisses := c.stats.Misses.Load()
			totalRequests := (currentHits - lastHits) + (currentMisses - lastMisses)
			qps := float64(totalRequests) / duration

			// 更新指标
			c.tuneMetrics.mu.Lock()
			c.tuneMetrics.qpsHistory = append(c.tuneMetrics.qpsHistory, qps)
			if len(c.tuneMetrics.qpsHistory) > 60 {
				c.tuneMetrics.qpsHistory = c.tuneMetrics.qpsHistory[1:]
			}

			// 计算命中率
			if totalRequests > 0 {
				c.tuneMetrics.avgHitRate = float64(currentHits-lastHits) / float64(totalRequests)
			}

			// 计算负载因子
			c.tuneMetrics.avgLoadFactor = float64(c.Size()) / float64(c.config.Capacity)
			c.tuneMetrics.mu.Unlock()

			// 每分钟执行一次调优决策
			if now.Sub(c.lastTuneTime) >= time.Minute {
				c.performTuning()
				c.lastTuneTime = now
			}

			lastHits = currentHits
			lastMisses = currentMisses
			lastCheck = now
		}
	}
}

// performTuning 执行调优决策
func (c *ShardedToolCache) performTuning() {
	c.tuneMetrics.mu.RLock()
	defer c.tuneMetrics.mu.RUnlock()

	if len(c.tuneMetrics.qpsHistory) < 6 {
		return // 需要至少1分钟的数据
	}

	// 计算平均QPS
	var avgQPS float64
	for _, qps := range c.tuneMetrics.qpsHistory {
		avgQPS += qps
	}
	avgQPS /= float64(len(c.tuneMetrics.qpsHistory))

	// 根据指标调整配置
	// 注意：分片数量在运行时不能更改，但可以记录建议供下次重启使用
	if avgQPS > 1000 && c.tuneMetrics.avgHitRate < 0.7 {
		log.Printf("Auto-tuning: High QPS (%.2f) with low hit rate (%.2f%%). Consider increasing cache capacity or TTL.",
			avgQPS, c.tuneMetrics.avgHitRate*100)
	}

	if c.tuneMetrics.avgLoadFactor > 0.95 {
		log.Printf("Auto-tuning: Cache nearly full (%.2f%%). Consider increasing capacity.",
			c.tuneMetrics.avgLoadFactor*100)
	}

	// 可以动态调整的参数示例：
	// - 调整清理间隔（已在adaptiveCleanup中实现）
	// - 记录性能建议供监控系统使用
}
