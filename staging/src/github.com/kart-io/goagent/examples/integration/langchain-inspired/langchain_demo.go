package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/kart-io/goagent/cache"
	"github.com/kart-io/goagent/core"
	"github.com/kart-io/goagent/parsers"
)

// ç¤ºä¾‹ 1: ä½¿ç”¨ Runnable æ¥å£å’Œç®¡é“æ¨¡å¼
func exampleRunnable() {
	fmt.Println("=== Example 1: Runnable Interface with Pipe ===")
	fmt.Println()

	// åˆ›å»ºä¸€ä¸ªç®€å•çš„ Runnable å‡½æ•°ï¼šæ–‡æœ¬è½¬å¤§å†™
	uppercaseRunnable := core.NewRunnableFunc(
		func(ctx context.Context, input string) (string, error) {
			return fmt.Sprintf("UPPERCASE: %s", input), nil
		},
	)

	// ä½¿ç”¨ Pipe è¿æ¥ä¸¤ä¸ª Runnable (ç±»ä¼¼ LangChain çš„ LCEL)
	// æ³¨æ„ï¼šç”±äº Go æ³›å‹é™åˆ¶ï¼ŒPipe è¿”å›ç±»å‹ä¸º Runnable[string, any]
	pipeline := uppercaseRunnable.Pipe(core.NewRunnableFunc(
		func(ctx context.Context, input string) (any, error) {
			return fmt.Sprintf("PREFIX -> %s", input), nil
		},
	))

	// æ‰§è¡Œ
	result, err := pipeline.Invoke(context.Background(), "hello world")
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("Input: hello world\n")
	fmt.Printf("Output: %s\n\n", result)
}

// ç¤ºä¾‹ 2: ä½¿ç”¨ Callbacks ç›‘æ§æ‰§è¡Œè¿‡ç¨‹
func exampleCallbacks() {
	fmt.Println("=== Example 2: Callbacks for Monitoring ===")
	fmt.Println()

	// åˆ›å»º Stdout å›è°ƒï¼ˆè¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰
	stdoutCallback := core.NewStdoutCallback(true) // å¯ç”¨é¢œè‰²

	// åˆ›å»º Metrics å›è°ƒï¼ˆæ”¶é›†æŒ‡æ ‡ï¼‰
	metricsCollector := &SimpleMetricsCollector{}
	metricsCallback := core.NewMetricsCallback(metricsCollector)

	// åˆ›å»ºå¸¦å›è°ƒçš„ Runnable
	processRunnable := core.NewRunnableFunc(
		func(ctx context.Context, input string) (string, error) {
			// æ¨¡æ‹Ÿ LLM è°ƒç”¨
			_ = stdoutCallback.OnLLMStart(ctx, []string{input}, "gpt-4")
			time.Sleep(100 * time.Millisecond) // æ¨¡æ‹Ÿå»¶è¿Ÿ
			result := fmt.Sprintf("Processed: %s", input)
			_ = stdoutCallback.OnLLMEnd(ctx, result, 50)
			return result, nil
		},
	).WithCallbacks(stdoutCallback, metricsCallback)

	// æ‰§è¡Œ
	result, _ := processRunnable.Invoke(context.Background(), "analyze system logs")
	fmt.Printf("\nResult: %s\n\n", result)

	// æŸ¥çœ‹æ”¶é›†çš„æŒ‡æ ‡
	fmt.Printf("Metrics Collected:\n")
	fmt.Printf("- Total Calls: %d\n", metricsCollector.calls)
	fmt.Printf("- Total Latency: %v\n\n", metricsCollector.totalLatency)
}

// ç¤ºä¾‹ 3: ä½¿ç”¨ Output Parsers è§£æç»“æ„åŒ–è¾“å‡º
func exampleOutputParsers() {
	fmt.Println("=== Example 3: Output Parsers for Structured Data ===")
	fmt.Println()

	// å®šä¹‰è¾“å‡ºç»“æ„
	type AnalysisResult struct {
		RootCause   string   `json:"root_cause" description:"The identified root cause"`
		Confidence  float64  `json:"confidence" description:"Confidence score 0-1"`
		Suggestions []string `json:"suggestions" description:"List of suggestions"`
	}

	// åˆ›å»º JSON è¾“å‡ºè§£æå™¨
	parser := parsers.NewJSONOutputParser[AnalysisResult](false)

	// æ¨¡æ‹Ÿ LLM è¿”å›çš„ JSON è¾“å‡ºï¼ˆå¸¦ markdown ä»£ç å—ï¼‰
	llmOutput := `
Based on the analysis, here are my findings:

` + "```json" + `
{
  "root_cause": "Database connection pool exhausted",
  "confidence": 0.95,
  "suggestions": [
    "Increase connection pool size",
    "Implement connection timeout",
    "Add connection retry logic"
  ]
}
` + "```" + `

These recommendations should resolve the issue.
`

	// è§£æè¾“å‡º
	result, err := parser.Parse(context.Background(), llmOutput)
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("Parsed Result:\n")
	fmt.Printf("- Root Cause: %s\n", result.RootCause)
	fmt.Printf("- Confidence: %.2f\n", result.Confidence)
	fmt.Printf("- Suggestions:\n")
	for _, suggestion := range result.Suggestions {
		fmt.Printf("  * %s\n", suggestion)
	}
	fmt.Println()

	// è·å–æ ¼å¼åŒ–æŒ‡ä»¤ï¼ˆç”¨äº promptï¼‰
	fmt.Printf("Format Instructions:\n%s\n\n", parser.GetFormatInstructions())
}

// ç¤ºä¾‹ 4: ä½¿ç”¨ Caching ä¼˜åŒ–æ€§èƒ½
func exampleCaching() {
	fmt.Println("=== Example 4: Caching for Performance ===")
	fmt.Println()

	// åˆ›å»ºå†…å­˜ç¼“å­˜ï¼ˆä½¿ç”¨ SimpleCacheï¼‰
	cacheInstance := cache.NewSimpleCache(5 * time.Minute)

	// åˆ›å»ºç¼“å­˜é”®ç”Ÿæˆå™¨
	keyGen := cache.NewCacheKeyGenerator("llm")

	// æ¨¡æ‹Ÿ LLM è°ƒç”¨ï¼ˆè€—æ—¶æ“ä½œï¼‰
	expensiveLLMCall := func(ctx context.Context, prompt string) string {
		// ç”Ÿæˆç¼“å­˜é”®
		key := keyGen.GenerateKeySimple(prompt)

		// æ£€æŸ¥ç¼“å­˜
		if cached, err := cacheInstance.Get(ctx, key); err == nil {
			fmt.Printf("ğŸš€ Cache HIT for prompt: %s\n", prompt)
			return cached.(string)
		}

		fmt.Printf("ğŸ’¤ Cache MISS for prompt: %s\n", prompt)

		// æ¨¡æ‹Ÿ LLM è°ƒç”¨å»¶è¿Ÿ
		time.Sleep(500 * time.Millisecond)
		result := fmt.Sprintf("LLM Response for: %s", prompt)

		// ç¼“å­˜ç»“æœ
		_ = cacheInstance.Set(ctx, key, result, 0)

		return result
	}

	// ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
	start := time.Now()
	result1 := expensiveLLMCall(context.Background(), "What is Kubernetes?")
	fmt.Printf("First call took: %v\n", time.Since(start))
	fmt.Printf("Result: %s\n\n", result1)

	// ç¬¬äºŒæ¬¡è°ƒç”¨ç›¸åŒé—®é¢˜ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
	start = time.Now()
	result2 := expensiveLLMCall(context.Background(), "What is Kubernetes?")
	fmt.Printf("Second call took: %v\n", time.Since(start))
	fmt.Printf("Result: %s\n\n", result2)

	// æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
	stats := cacheInstance.GetStats()
	fmt.Printf("Cache Stats:\n")
	fmt.Printf("- Hits: %d\n", stats.Hits)
	fmt.Printf("- Misses: %d\n", stats.Misses)
	fmt.Printf("- Hit Rate: %.2f%%\n", stats.HitRate*100)
	fmt.Printf("- Size: %d/%d\n\n", stats.Size, stats.MaxSize)
}

// ç¤ºä¾‹ 5: ç»¼åˆåº”ç”¨ - LangChain é£æ ¼çš„ RAG Pipeline
func exampleRAGPipeline() {
	fmt.Println("=== Example 5: LangChain-style RAG Pipeline ===")
	fmt.Println()

	// å®šä¹‰ç»“æ„åŒ–è¾“å‡º
	type RAGResponse struct {
		Answer     string   `json:"answer"`
		Sources    []string `json:"sources"`
		Confidence float64  `json:"confidence"`
	}

	// åˆ›å»ºç»„ä»¶ï¼ˆä½¿ç”¨ SimpleCacheï¼‰
	cacheInstance := cache.NewSimpleCache(5 * time.Minute)
	parser := parsers.NewJSONOutputParser[RAGResponse](false)
	stdoutCallback := core.NewStdoutCallback(true)

	// Step 1: æ£€ç´¢ç›¸å…³æ–‡æ¡£ (Retrieval)
	retrievalStep := core.NewRunnableFunc(
		func(ctx context.Context, query string) ([]string, error) {
			_ = stdoutCallback.OnToolStart(ctx, "VectorStoreRetriever", query)
			// æ¨¡æ‹Ÿä»å‘é‡æ•°æ®åº“æ£€ç´¢
			docs := []string{
				"Kubernetes is a container orchestration platform",
				"K8s provides automated deployment and scaling",
				"Pods are the smallest deployable units in Kubernetes",
			}
			_ = stdoutCallback.OnToolEnd(ctx, "VectorStoreRetriever", fmt.Sprintf("%v", docs))
			return docs, nil
		},
	)

	// Step 2: ç”Ÿæˆ Prompt (Augment)
	promptStep := core.NewRunnableFunc(
		func(ctx context.Context, input []string) (string, error) {
			query := "What is Kubernetes?" // ç®€åŒ–ç¤ºä¾‹
			docs := input
			prompt := fmt.Sprintf(
				"Context:\n%s\n\nQuestion: %s\n\n%s",
				fmt.Sprintf("%v", docs),
				query,
				parser.GetFormatInstructions(),
			)
			return prompt, nil
		},
	)

	// Step 3: è°ƒç”¨ LLM (Generate)
	llmStep := core.NewRunnableFunc(
		func(ctx context.Context, prompt string) (string, error) {
			_ = stdoutCallback.OnLLMStart(ctx, []string{prompt}, "gpt-4")

			// æ£€æŸ¥ç¼“å­˜
			keyGen := cache.NewCacheKeyGenerator("rag")
			key := keyGen.GenerateKeySimple(prompt)

			if cached, err := cacheInstance.Get(ctx, key); err == nil {
				_ = stdoutCallback.OnLLMEnd(ctx, cached.(string), 0)
				return cached.(string), nil
			}

			// æ¨¡æ‹Ÿ LLM è°ƒç”¨
			time.Sleep(200 * time.Millisecond)
			response := `
` + "```json" + `
{
  "answer": "Kubernetes is a container orchestration platform that provides automated deployment, scaling, and management of containerized applications.",
  "sources": ["doc1", "doc2"],
  "confidence": 0.92
}
` + "```" + `
`
			_ = cacheInstance.Set(ctx, key, response, 0)
			_ = stdoutCallback.OnLLMEnd(ctx, response, 150)
			return response, nil
		},
	)

	// Step 4: è§£æè¾“å‡º
	parseStep := core.NewRunnableFunc(
		func(ctx context.Context, llmOutput string) (RAGResponse, error) {
			return parser.Parse(ctx, llmOutput)
		},
	)

	// æ„å»º RAG ç®¡é“ (ç±»ä¼¼ LangChain çš„ LCEL)
	// æ³¨æ„ï¼šç”±äº Go æ³›å‹é™åˆ¶ï¼Œéœ€è¦å°†ä¸­é—´æ­¥éª¤çš„è¿”å›ç±»å‹è°ƒæ•´ä¸º any
	ragPipeline := retrievalStep.
		Pipe(core.NewRunnableFunc(func(ctx context.Context, input []string) (any, error) {
			return promptStep.Invoke(ctx, input)
		})).
		Pipe(core.NewRunnableFunc(func(ctx context.Context, input any) (any, error) {
			return llmStep.Invoke(ctx, input.(string))
		})).
		Pipe(core.NewRunnableFunc(func(ctx context.Context, input any) (any, error) {
			return parseStep.Invoke(ctx, input.(string))
		})).
		WithCallbacks(stdoutCallback)

	// æ‰§è¡Œ RAG æŸ¥è¯¢
	fmt.Println("Executing RAG Pipeline...")
	fmt.Println()
	result, err := ragPipeline.Invoke(context.Background(), "What is Kubernetes?")
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("\nâœ… RAG Pipeline Result:\n")
	ragResp := result.(RAGResponse)
	fmt.Printf("Answer: %s\n", ragResp.Answer)
	fmt.Printf("Sources: %v\n", ragResp.Sources)
	fmt.Printf("Confidence: %.2f\n\n", ragResp.Confidence)
}

// ç¤ºä¾‹ 6: æ‰¹å¤„ç†å’Œå¹¶å‘æ‰§è¡Œ
func exampleBatchProcessing() {
	fmt.Println("=== Example 6: Batch Processing ===")
	fmt.Println()

	// åˆ›å»ºå¤„ç† Runnable
	processor := core.NewRunnableFunc(
		func(ctx context.Context, input string) (string, error) {
			// æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
			time.Sleep(100 * time.Millisecond)
			return fmt.Sprintf("Processed: %s", input), nil
		},
	)

	// æ‰¹é‡è¾“å…¥
	inputs := []string{
		"task 1",
		"task 2",
		"task 3",
		"task 4",
		"task 5",
	}

	// æ‰¹é‡æ‰§è¡Œï¼ˆå¹¶å‘å¤„ç†ï¼‰
	fmt.Printf("Processing %d tasks in batch...\n", len(inputs))
	start := time.Now()

	results, err := processor.Batch(context.Background(), inputs)
	if err != nil {
		log.Fatal(err)
	}

	duration := time.Since(start)
	fmt.Printf("Completed in: %v\n", duration)
	fmt.Printf("Results:\n")
	for i, result := range results {
		fmt.Printf("  %d. %s\n", i+1, result)
	}
	fmt.Println()
}

// SimpleMetricsCollector ç®€å•çš„æŒ‡æ ‡æ”¶é›†å™¨å®ç°
type SimpleMetricsCollector struct {
	calls        int64
	totalLatency time.Duration
}

func (m *SimpleMetricsCollector) IncrementCounter(name string, value int64, tags map[string]string) {
	m.calls += value
}

func (m *SimpleMetricsCollector) RecordHistogram(name string, value float64, tags map[string]string) {
	if name == "llm.latency" {
		m.totalLatency += time.Duration(value * float64(time.Second))
	}
}

func (m *SimpleMetricsCollector) RecordGauge(name string, value float64, tags map[string]string) {
	// No-op for this example
}

func main() {
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘  LangChain-Inspired pkg/agent Examples                   â•‘")
	fmt.Println("â•‘  Demonstrating Runnable, Callbacks, Parsers, and Cache   â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
	exampleRunnable()
	exampleCallbacks()
	exampleOutputParsers()
	exampleCaching()
	exampleRAGPipeline()
	exampleBatchProcessing()

	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘  All Examples Completed Successfully! ğŸ‰                  â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
}
