package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/kart-io/goagent/llm"
	"github.com/kart-io/goagent/llm/providers"
	"github.com/kart-io/goagent/multiagent"
	"github.com/kart-io/goagent/utils/json"
	"github.com/nats-io/nats.go"
)

// AIAgent é›†æˆ LLM çš„æ™ºèƒ½ä»£ç†
type AIAgent struct {
	ID           string
	Role         string
	LLMClient    llm.Client
	Comm         multiagent.Communicator
	Description  string
	SystemPrompt string
}

// NewAIAgent åˆ›å»º AI ä»£ç†
func NewAIAgent(id, role, systemPrompt, description string, llmClient llm.Client, store multiagent.ChannelStore) (*AIAgent, error) {
	// åˆ›å»ºå¸¦ NATS çš„é€šä¿¡å™¨
	comm := multiagent.NewMemoryCommunicatorWithStore(id, store)

	return &AIAgent{
		ID:           id,
		Role:         role,
		LLMClient:    llmClient,
		Comm:         comm,
		Description:  description,
		SystemPrompt: systemPrompt,
	}, nil
}

// ProcessMessage å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯å¹¶ç”¨ LLM ç”Ÿæˆå“åº”
func (a *AIAgent) ProcessMessage(ctx context.Context, msg *multiagent.AgentMessage) (string, error) {
	// æ„å»ºæç¤ºè¯ - ç»“åˆç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æ¶ˆæ¯
	userMessage := fmt.Sprintf(`You received a message from %s:
Message Type: %s
Content: %v

Please provide a concise, helpful response based on your role.`,
		msg.From, msg.Type, msg.Payload)

	// è°ƒç”¨ LLM
	messages := []llm.Message{
		llm.SystemMessage(a.SystemPrompt),
		llm.UserMessage(userMessage),
	}

	response, err := a.LLMClient.Chat(ctx, messages)
	if err != nil {
		return "", fmt.Errorf("LLM chat failed: %w", err)
	}

	return response.Content, nil
}

// Listen ç›‘å¬æ¶ˆæ¯å¹¶å¤„ç†
func (a *AIAgent) Listen(ctx context.Context, wg *sync.WaitGroup) {
	defer wg.Done()

	fmt.Printf("[%s] Starting to listen for messages...\n", a.ID)

	for {
		select {
		case <-ctx.Done():
			fmt.Printf("[%s] Stopping listener\n", a.ID)
			return
		default:
			// æ¥æ”¶æ¶ˆæ¯ï¼ˆå¸¦è¶…æ—¶ï¼‰
			msgCtx, cancel := context.WithTimeout(ctx, 2*time.Second)
			msg, err := a.Comm.Receive(msgCtx)
			cancel()

			if err != nil {
				if err == context.DeadlineExceeded || err == context.Canceled {
					continue
				}
				log.Printf("[%s] Error receiving message: %v", a.ID, err)
				continue
			}

			fmt.Printf("\n[%s] ğŸ“¨ Received message from %s\n", a.ID, msg.From)
			fmt.Printf("[%s] Message Type: %s\n", a.ID, msg.Type)
			fmt.Printf("[%s] Content: %v\n", a.ID, msg.Payload)

			// ä½¿ç”¨ LLM å¤„ç†æ¶ˆæ¯
			fmt.Printf("[%s] ğŸ¤– Processing with AI...\n", a.ID)
			response, err := a.ProcessMessage(ctx, msg)
			if err != nil {
				log.Printf("[%s] Error processing message: %v", a.ID, err)
				continue
			}

			fmt.Printf("[%s] ğŸ’¡ AI Response: %s\n", a.ID, response)

			// å›å¤å‘é€è€…
			if msg.Type == multiagent.MessageTypeRequest || msg.Type == multiagent.MessageTypeCommand {
				replyMsg := multiagent.NewAgentMessage(
					a.ID,
					msg.From,
					multiagent.MessageTypeResponse,
					map[string]interface{}{
						"original_request": msg.Payload,
						"ai_response":      response,
						"processed_at":     time.Now().Format(time.RFC3339),
					},
				)

				if err := a.Comm.Send(ctx, msg.From, replyMsg); err != nil {
					log.Printf("[%s] Error sending reply: %v", a.ID, err)
				} else {
					fmt.Printf("[%s] âœ… Sent reply to %s\n\n", a.ID, msg.From)
				}
			}
		}
	}
}

// SendRequest å‘é€è¯·æ±‚å¹¶ç­‰å¾…å“åº”
func (a *AIAgent) SendRequest(ctx context.Context, targetID, request string) (string, error) {
	msg := multiagent.NewAgentMessage(
		a.ID,
		targetID,
		multiagent.MessageTypeRequest,
		request,
	)

	fmt.Printf("[%s] ğŸ“¤ Sending request to %s: %s\n", a.ID, targetID, request)

	if err := a.Comm.Send(ctx, targetID, msg); err != nil {
		return "", err
	}

	// ç­‰å¾…å“åº”
	responseCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
	defer cancel()

	response, err := a.Comm.Receive(responseCtx)
	if err != nil {
		return "", fmt.Errorf("timeout waiting for response: %w", err)
	}

	// æå– AI å“åº”
	if payload, ok := response.Payload.(map[string]interface{}); ok {
		if aiResponse, ok := payload["ai_response"].(string); ok {
			return aiResponse, nil
		}
	}

	// å›é€€ï¼šè¿”å›åŸå§‹ payload
	payloadBytes, _ := json.Marshal(response.Payload)
	return string(payloadBytes), nil
}

// Close å…³é—­ä»£ç†
func (a *AIAgent) Close() error {
	return a.Comm.Close()
}

// RunAICollaboration è¿è¡Œ AI ä»£ç†åä½œç¤ºä¾‹
func RunAICollaboration() {
	fmt.Println("=== AI-Powered Multi-Agent Collaboration via NATS ===")
	fmt.Println()

	// è·å– DeepSeek API å¯†é’¥
	apiKey := os.Getenv("DEEPSEEK_API_KEY")
	if apiKey == "" {
		log.Fatal("âŒ DEEPSEEK_API_KEY environment variable is required\n" +
			"Get your key from: https://platform.deepseek.com/")
	}

	// è·å– NATS URL
	natsURL := os.Getenv("NATS_URL")
	if natsURL == "" {
		natsURL = nats.DefaultURL
	}

	fmt.Printf("Connecting to NATS: %s\n", natsURL)

	// åˆ›å»º NATS ChannelStore
	natsStore, err := NewNATSChannelStore(natsURL)
	if err != nil {
		log.Fatalf("âŒ Failed to connect to NATS: %v\n"+
			"Please start NATS: ./test.sh start", err)
	}
	defer func() {
		if err := natsStore.Close(); err != nil {
			log.Printf("Warning: failed to close NATS store: %v", err)
		}
	}()

	fmt.Println("âœ… Connected to NATS")
	fmt.Println()

	// åˆ›å»º DeepSeek LLM å®¢æˆ·ç«¯
	llmClient, err := providers.NewDeepSeekWithOptions(
		llm.WithAPIKey(apiKey),
		llm.WithModel("deepseek-chat"),
		llm.WithTemperature(0.7),
		llm.WithMaxTokens(2000),
		llm.WithTimeout(30),
	)
	if err != nil {
		log.Fatalf("âŒ Failed to create DeepSeek client: %v", err)
	}

	// åˆ›å»ºä¸‰ä¸ªä¸“ä¸šåŒ–çš„ AI ä»£ç†
	fmt.Println("Creating AI Agents...")

	// 1. åè°ƒä»£ç†ï¼šè´Ÿè´£ä»»åŠ¡åˆ†é…å’Œç»“æœæ±‡æ€»
	coordinator, err := NewAIAgent(
		"coordinator",
		"Project Coordinator",
		`You are a Project Coordinator AI Agent. Your role is to:
- Break down complex tasks into smaller subtasks
- Assign tasks to appropriate specialist agents
- Collect and synthesize results from multiple agents
- Provide final comprehensive reports
Be concise and professional.`,
		"Coordinates multi-agent collaboration and task distribution",
		llmClient,
		natsStore,
	)
	if err != nil {
		log.Fatalf("Failed to create coordinator: %v", err)
	}

	// 2. ç ”ç©¶ä»£ç†ï¼šè´Ÿè´£ä¿¡æ¯æ”¶é›†å’Œåˆ†æ
	researcher, err := NewAIAgent(
		"researcher",
		"Research Specialist",
		`You are a Research Specialist AI Agent. Your role is to:
- Gather and analyze information
- Provide detailed research findings
- Answer questions with evidence-based responses
- Present findings in 3 key points
Be thorough but concise.`,
		"Specializes in information gathering and analysis",
		llmClient,
		natsStore,
	)
	if err != nil {
		log.Fatalf("Failed to create researcher: %v", err)
	}

	// 3. æŠ€æœ¯ä¸“å®¶ä»£ç†ï¼šè´Ÿè´£æŠ€æœ¯é—®é¢˜è§£ç­”
	techExpert, err := NewAIAgent(
		"tech-expert",
		"Technical Expert",
		`You are a Technical Expert AI Agent. Your role is to:
- Provide technical solutions and recommendations
- Suggest specific technologies and tools
- Give practical, actionable advice
- Present recommendations in a numbered list
Be practical and solution-oriented.`,
		"Provides technical expertise and solutions",
		llmClient,
		natsStore,
	)
	if err != nil {
		log.Fatalf("Failed to create tech expert: %v", err)
	}

	fmt.Printf("âœ… Created %s\n", coordinator.ID)
	fmt.Printf("âœ… Created %s\n", researcher.ID)
	fmt.Printf("âœ… Created %s\n", techExpert.ID)
	fmt.Println()

	// å¯åŠ¨ä»£ç†ç›‘å¬å™¨
	ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cancel()

	var wg sync.WaitGroup

	// å¯åŠ¨ç ”ç©¶ä»£ç†å’ŒæŠ€æœ¯ä¸“å®¶çš„ç›‘å¬å™¨
	wg.Add(2)
	go researcher.Listen(ctx, &wg)
	go techExpert.Listen(ctx, &wg)

	// ç»™ç›‘å¬å™¨æ—¶é—´å¯åŠ¨
	time.Sleep(500 * time.Millisecond)

	// åœºæ™¯ï¼šåè°ƒä»£ç†å‘å…¶ä»–ä»£ç†è¯·æ±‚ä¿¡æ¯ï¼Œç„¶åæ±‡æ€»ç»“æœ
	fmt.Println("=== Collaboration Scenario: Building a Microservices Architecture ===")
	fmt.Println()

	// 1. åè°ƒä»£ç†è¯¢é—®ç ”ç©¶ä»£ç†
	fmt.Println("Step 1: Coordinator asks Researcher about microservices best practices")
	fmt.Println(strings.Repeat("-", 80))

	researchResponse, err := coordinator.SendRequest(ctx, "researcher",
		"What are the key benefits and challenges of microservices architecture? Provide 3 main points for each.")
	if err != nil {
		log.Fatalf("Error communicating with researcher: %v", err)
	}

	fmt.Printf("\nğŸ“Š Research Findings:\n%s\n\n", researchResponse)

	// 2. åè°ƒä»£ç†è¯¢é—®æŠ€æœ¯ä¸“å®¶
	fmt.Println("Step 2: Coordinator asks Tech Expert about implementation")
	fmt.Println(strings.Repeat("-", 80))

	techResponse, err := coordinator.SendRequest(ctx, "tech-expert",
		"What technologies and tools would you recommend for building a microservices system? List 3 key technologies with brief explanations.")
	if err != nil {
		log.Fatalf("Error communicating with tech expert: %v", err)
	}

	fmt.Printf("\nğŸ”§ Technical Recommendations:\n%s\n\n", techResponse)

	// 3. åè°ƒä»£ç†æ±‡æ€»æ‰€æœ‰ä¿¡æ¯
	fmt.Println("Step 3: Coordinator synthesizes all information")
	fmt.Println(strings.Repeat("-", 80))

	// ä½¿ç”¨ LLM ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
	finalPrompt := fmt.Sprintf(`You are the Project Coordinator. You've collected information from team members:

RESEARCH FINDINGS:
%s

TECHNICAL RECOMMENDATIONS:
%s

Please create a concise executive summary (3-4 sentences) that combines these insights to recommend whether and how to proceed with microservices architecture.`,
		researchResponse, techResponse)

	finalMessages := []llm.Message{
		llm.UserMessage(finalPrompt),
	}

	finalOutput, err := llmClient.Chat(ctx, finalMessages)
	if err != nil {
		log.Fatalf("Error generating final report: %v", err)
	}

	fmt.Printf("\nğŸ“‹ Executive Summary:\n%s\n\n", finalOutput.Content)

	// å…³é—­ä»£ç†
	fmt.Println("Shutting down agents...")
	cancel() // åœæ­¢ç›‘å¬å™¨

	wg.Wait() // ç­‰å¾…ç›‘å¬å™¨é€€å‡º

	if err := coordinator.Close(); err != nil {
		log.Printf("Warning: failed to close coordinator: %v", err)
	}
	if err := researcher.Close(); err != nil {
		log.Printf("Warning: failed to close researcher: %v", err)
	}
	if err := techExpert.Close(); err != nil {
		log.Printf("Warning: failed to close techExpert: %v", err)
	}

	fmt.Println()
	fmt.Println("=== AI Collaboration Completed Successfully ===")
	fmt.Println()
	fmt.Println("This example demonstrated:")
	fmt.Println("âœ… Multiple AI agents with specialized roles")
	fmt.Println("âœ… Distributed communication via NATS")
	fmt.Println("âœ… Inter-agent collaboration using LLMs")
	fmt.Println("âœ… Information synthesis from multiple sources")
	fmt.Println("âœ… Real-world problem solving with AI agents")
}
