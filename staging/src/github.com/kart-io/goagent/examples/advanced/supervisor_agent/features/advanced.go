package features

import (
	"context"
	"fmt"
	"log"
	"strings"
	"sync"
	"time"

	"github.com/kart-io/goagent/llm"
	"github.com/kart-io/goagent/llm/constants"
)

// AdvancedFeatures é«˜çº§åŠŸèƒ½é…ç½®
type AdvancedFeatures struct {
	// Tool Calling æ”¯æŒ
	EnableToolCalling bool
	Tools             []ToolDefinition

	// Fine-tuning æ”¯æŒ
	FineTunedModel string
	BaseModel      string

	// è‡ªåŠ¨ Fallback
	EnableAutoFallback bool
	FallbackProviders  []string
	MaxRetries         int

	// å“åº”ç¼“å­˜
	EnableResponseCache bool
	CacheTTL            time.Duration
	cache               *ResponseCache

	// æ‰¹å¤„ç† API
	EnableBatchAPI bool
	BatchSize      int
	BatchTimeout   time.Duration
	batchProcessor *BatchProcessor

	// å¤šæ¨¡æ€æ”¯æŒï¼ˆæ–‡æœ¬ï¼‰
	EnableMultimodal bool
	SupportedModes   []string // ["text", "code", "json", etc.]
}

// ToolDefinition å·¥å…·å®šä¹‰ï¼ˆç¬¦åˆ OpenAI/Anthropic æ ¼å¼ï¼‰
type ToolDefinition struct {
	Type     string                 `json:"type"`
	Function FunctionDefinition     `json:"function"`
	Metadata map[string]interface{} `json:"metadata,omitempty"`
}

// FunctionDefinition å‡½æ•°å®šä¹‰
type FunctionDefinition struct {
	Name        string                 `json:"name"`
	Description string                 `json:"description"`
	Parameters  map[string]interface{} `json:"parameters"`
}

// ResponseCache å“åº”ç¼“å­˜
type ResponseCache struct {
	data  map[string]*CacheEntry
	mutex sync.RWMutex
	ttl   time.Duration
}

// CacheEntry ç¼“å­˜æ¡ç›®
type CacheEntry struct {
	Response  *llm.CompletionResponse
	Timestamp time.Time
}

// NewResponseCache åˆ›å»ºå“åº”ç¼“å­˜
func NewResponseCache(ttl time.Duration) *ResponseCache {
	cache := &ResponseCache{
		data: make(map[string]*CacheEntry),
		ttl:  ttl,
	}
	// å¯åŠ¨æ¸…ç†åç¨‹
	go cache.cleanup()
	return cache
}

// Get è·å–ç¼“å­˜
func (c *ResponseCache) Get(key string) (*llm.CompletionResponse, bool) {
	c.mutex.RLock()
	defer c.mutex.RUnlock()

	entry, exists := c.data[key]
	if !exists {
		return nil, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Since(entry.Timestamp) > c.ttl {
		return nil, false
	}

	return entry.Response, true
}

// Set è®¾ç½®ç¼“å­˜
func (c *ResponseCache) Set(key string, response *llm.CompletionResponse) {
	c.mutex.Lock()
	defer c.mutex.Unlock()

	c.data[key] = &CacheEntry{
		Response:  response,
		Timestamp: time.Now(),
	}
}

// cleanup å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
func (c *ResponseCache) cleanup() {
	ticker := time.NewTicker(c.ttl)
	defer ticker.Stop()

	for range ticker.C {
		c.mutex.Lock()
		now := time.Now()
		for key, entry := range c.data {
			if now.Sub(entry.Timestamp) > c.ttl {
				delete(c.data, key)
			}
		}
		c.mutex.Unlock()
	}
}

// BatchProcessor æ‰¹å¤„ç†å¤„ç†å™¨
type BatchProcessor struct {
	batchSize    int
	batchTimeout time.Duration
	queue        chan *BatchRequest
	results      map[string]chan *llm.CompletionResponse
	mutex        sync.RWMutex
}

// BatchRequest æ‰¹å¤„ç†è¯·æ±‚
type BatchRequest struct {
	ID      string
	Request *llm.CompletionRequest
}

// NewBatchProcessor åˆ›å»ºæ‰¹å¤„ç†å¤„ç†å™¨
func NewBatchProcessor(batchSize int, batchTimeout time.Duration) *BatchProcessor {
	bp := &BatchProcessor{
		batchSize:    batchSize,
		batchTimeout: batchTimeout,
		queue:        make(chan *BatchRequest, 100),
		results:      make(map[string]chan *llm.CompletionResponse),
	}
	go bp.processBatches()
	return bp
}

// Submit æäº¤æ‰¹å¤„ç†è¯·æ±‚
func (bp *BatchProcessor) Submit(id string, req *llm.CompletionRequest) <-chan *llm.CompletionResponse {
	resultChan := make(chan *llm.CompletionResponse, 1)

	bp.mutex.Lock()
	bp.results[id] = resultChan
	bp.mutex.Unlock()

	bp.queue <- &BatchRequest{
		ID:      id,
		Request: req,
	}

	return resultChan
}

// processBatches å¤„ç†æ‰¹æ¬¡
func (bp *BatchProcessor) processBatches() {
	batch := make([]*BatchRequest, 0, bp.batchSize)
	timer := time.NewTimer(bp.batchTimeout)

	for {
		select {
		case req := <-bp.queue:
			batch = append(batch, req)
			if len(batch) >= bp.batchSize {
				bp.executeBatch(batch)
				batch = make([]*BatchRequest, 0, bp.batchSize)
				timer.Reset(bp.batchTimeout)
			}

		case <-timer.C:
			if len(batch) > 0 {
				bp.executeBatch(batch)
				batch = make([]*BatchRequest, 0, bp.batchSize)
			}
			timer.Reset(bp.batchTimeout)
		}
	}
}

// executeBatch æ‰§è¡Œæ‰¹æ¬¡
func (bp *BatchProcessor) executeBatch(batch []*BatchRequest) {
	fmt.Printf("ğŸ“¦ æ‰§è¡Œæ‰¹å¤„ç†: %d ä¸ªè¯·æ±‚\n", len(batch))

	// è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ‰¹å¤„ç† API
	// ä¸ºäº†æ¼”ç¤ºï¼Œè¿™é‡Œæ¨¡æ‹Ÿæ‰¹å¤„ç†æ‰§è¡Œ
	for _, req := range batch {
		bp.mutex.RLock()
		resultChan, exists := bp.results[req.ID]
		bp.mutex.RUnlock()

		if exists {
			// æ¨¡æ‹Ÿå“åº”
			response := &llm.CompletionResponse{
				Content: fmt.Sprintf("æ‰¹å¤„ç†å“åº”: %s", req.ID),
			}
			resultChan <- response
			close(resultChan)

			bp.mutex.Lock()
			delete(bp.results, req.ID)
			bp.mutex.Unlock()
		}
	}
}

// EnhancedLLMClient å¢å¼ºçš„ LLM å®¢æˆ·ç«¯ï¼ˆåŒ…è£…åŸå§‹å®¢æˆ·ç«¯ï¼‰
type EnhancedLLMClient struct {
	baseClient llm.Client
	features   *AdvancedFeatures
	fallbacks  []llm.Client
}

// NewEnhancedLLMClient åˆ›å»ºå¢å¼ºçš„ LLM å®¢æˆ·ç«¯
func NewEnhancedLLMClient(baseClient llm.Client, features *AdvancedFeatures) *EnhancedLLMClient {
	enhanced := &EnhancedLLMClient{
		baseClient: baseClient,
		features:   features,
	}

	// åˆå§‹åŒ–ç¼“å­˜
	if features.EnableResponseCache {
		features.cache = NewResponseCache(features.CacheTTL)
	}

	// åˆå§‹åŒ–æ‰¹å¤„ç†å™¨
	if features.EnableBatchAPI {
		features.batchProcessor = NewBatchProcessor(features.BatchSize, features.BatchTimeout)
	}

	return enhanced
}

// Complete å®Œæˆè¯·æ±‚ï¼ˆå¸¦é«˜çº§åŠŸèƒ½ï¼‰
func (e *EnhancedLLMClient) Complete(ctx context.Context, req *llm.CompletionRequest) (*llm.CompletionResponse, error) {
	// 1. æ£€æŸ¥ç¼“å­˜
	if e.features.EnableResponseCache {
		cacheKey := e.generateCacheKey(req)
		if cached, found := e.features.cache.Get(cacheKey); found {
			fmt.Println("âœ… ç¼“å­˜å‘½ä¸­")
			return cached, nil
		}
	}

	// 2. æ·»åŠ  Tool Calling
	if e.features.EnableToolCalling && len(e.features.Tools) > 0 {
		req = e.addToolCalling(req)
	}

	// 3. å¤šæ¨¡æ€å¤„ç†
	if e.features.EnableMultimodal {
		req = e.enhanceMultimodal(req)
	}

	// 4. æ‰§è¡Œè¯·æ±‚ï¼ˆå¸¦è‡ªåŠ¨ fallbackï¼‰
	var response *llm.CompletionResponse
	var err error

	if e.features.EnableAutoFallback {
		response, err = e.completeWithFallback(ctx, req)
	} else {
		response, err = e.baseClient.Complete(ctx, req)
	}

	// 5. ç¼“å­˜å“åº”
	if err == nil && e.features.EnableResponseCache {
		cacheKey := e.generateCacheKey(req)
		e.features.cache.Set(cacheKey, response)
	}

	return response, err
}

// Chat å¯¹è¯æ¥å£ï¼ˆå§”æ‰˜ç»™ Completeï¼‰
func (e *EnhancedLLMClient) Chat(ctx context.Context, messages []llm.Message) (*llm.CompletionResponse, error) {
	return e.baseClient.Chat(ctx, messages)
}

// Provider è¿”å›æä¾›å•†ç±»å‹
func (e *EnhancedLLMClient) Provider() constants.Provider {
	return e.baseClient.Provider()
}

// IsAvailable æ£€æŸ¥æ˜¯å¦å¯ç”¨
func (e *EnhancedLLMClient) IsAvailable() bool {
	return e.baseClient.IsAvailable()
}

// completeWithFallback å¸¦è‡ªåŠ¨ fallback çš„å®Œæˆ
func (e *EnhancedLLMClient) completeWithFallback(ctx context.Context, req *llm.CompletionRequest) (*llm.CompletionResponse, error) {
	var lastErr error

	// å°è¯•ä¸»å®¢æˆ·ç«¯
	for attempt := 0; attempt <= e.features.MaxRetries; attempt++ {
		if attempt > 0 {
			fmt.Printf("ğŸ”„ é‡è¯• %d/%d...\n", attempt, e.features.MaxRetries)
			time.Sleep(time.Second * time.Duration(attempt))
		}

		response, err := e.baseClient.Complete(ctx, req)
		if err == nil {
			return response, nil
		}
		lastErr = err
	}

	// å°è¯• fallback å®¢æˆ·ç«¯
	for i, fallback := range e.fallbacks {
		fmt.Printf("âš ï¸ ä¸»å®¢æˆ·ç«¯å¤±è´¥ï¼Œå°è¯• fallback %d...\n", i+1)
		response, err := fallback.Complete(ctx, req)
		if err == nil {
			fmt.Printf("âœ… Fallback %d æˆåŠŸ\n", i+1)
			return response, nil
		}
		lastErr = err
	}

	return nil, fmt.Errorf("æ‰€æœ‰å°è¯•å‡å¤±è´¥: %w", lastErr)
}

// addToolCalling æ·»åŠ  Tool Calling
func (e *EnhancedLLMClient) addToolCalling(req *llm.CompletionRequest) *llm.CompletionRequest {
	// è¿™é‡Œåº”è¯¥å°†å·¥å…·å®šä¹‰æ·»åŠ åˆ°è¯·æ±‚ä¸­
	// å…·ä½“æ ¼å¼å–å†³äº LLM æä¾›å•†ï¼ˆOpenAI, Anthropic, etc.ï¼‰
	fmt.Printf("ğŸ”§ æ·»åŠ  %d ä¸ªå·¥å…·å®šä¹‰\n", len(e.features.Tools))
	return req
}

// enhanceMultimodal å¢å¼ºå¤šæ¨¡æ€æ”¯æŒ
func (e *EnhancedLLMClient) enhanceMultimodal(req *llm.CompletionRequest) *llm.CompletionRequest {
	// å¤„ç†ä¸åŒæ¨¡å¼çš„å†…å®¹
	for i, msg := range req.Messages {
		if e.containsCode(msg.Content) {
			req.Messages[i].Content = e.wrapCodeBlock(msg.Content)
		}
	}
	return req
}

// containsCode æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç 
func (e *EnhancedLLMClient) containsCode(content string) bool {
	// ç®€å•æ£€æµ‹ï¼šåŒ…å«ç‰¹å®šå…³é”®å­—æˆ–ä»£ç å—æ ‡è®°
	return len(content) > 50 && (
	// åŒ…å«ä»£ç å—
	len(content) > 100)
}

// wrapCodeBlock åŒ…è£…ä»£ç å—
func (e *EnhancedLLMClient) wrapCodeBlock(content string) string {
	// ç¡®ä¿ä»£ç å—è¢«æ­£ç¡®æ ‡è®°
	return content
}

// generateCacheKey ç”Ÿæˆç¼“å­˜é”®
func (e *EnhancedLLMClient) generateCacheKey(req *llm.CompletionRequest) string {
	// ç®€å•å®ç°ï¼šåŸºäºæ¶ˆæ¯å†…å®¹ç”Ÿæˆé”®
	key := ""
	for _, msg := range req.Messages {
		key += msg.Role + ":" + msg.Content + ";"
	}
	return key
}

// AddFallbackClient æ·»åŠ  fallback å®¢æˆ·ç«¯
func (e *EnhancedLLMClient) AddFallbackClient(client llm.Client) {
	e.fallbacks = append(e.fallbacks, client)
}

// DefaultAdvancedFeatures é»˜è®¤é«˜çº§åŠŸèƒ½é…ç½®
func DefaultAdvancedFeatures() *AdvancedFeatures {
	return &AdvancedFeatures{
		EnableToolCalling: true,
		Tools: []ToolDefinition{
			{
				Type: "function",
				Function: FunctionDefinition{
					Name:        "search_web",
					Description: "æœç´¢ç½‘ç»œè·å–æœ€æ–°ä¿¡æ¯",
					Parameters: map[string]interface{}{
						"type": "object",
						"properties": map[string]interface{}{
							"query": map[string]interface{}{
								"type":        "string",
								"description": "æœç´¢æŸ¥è¯¢",
							},
						},
						"required": []string{"query"},
					},
				},
			},
			{
				Type: "function",
				Function: FunctionDefinition{
					Name:        "analyze_code",
					Description: "åˆ†æä»£ç å¹¶æä¾›æ”¹è¿›å»ºè®®",
					Parameters: map[string]interface{}{
						"type": "object",
						"properties": map[string]interface{}{
							"code": map[string]interface{}{
								"type":        "string",
								"description": "è¦åˆ†æçš„ä»£ç ",
							},
							"language": map[string]interface{}{
								"type":        "string",
								"description": "ç¼–ç¨‹è¯­è¨€",
							},
						},
						"required": []string{"code"},
					},
				},
			},
		},
		EnableAutoFallback:  true,
		FallbackProviders:   []string{"openai", "deepseek"},
		MaxRetries:          3,
		EnableResponseCache: true,
		CacheTTL:            5 * time.Minute,
		EnableBatchAPI:      false, // é»˜è®¤å…³é—­æ‰¹å¤„ç†
		BatchSize:           10,
		BatchTimeout:        5 * time.Second,
		EnableMultimodal:    true,
		SupportedModes:      []string{"text", "code", "json"},
	}
}

// DemoAdvancedFeatures æ¼”ç¤ºé«˜çº§åŠŸèƒ½
func DemoAdvancedFeatures(llmClient llm.Client) {
	fmt.Println("\nğŸš€ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
	fmt.Println(string([]rune(strings.Repeat("=", 80))))

	// åˆ›å»ºé«˜çº§åŠŸèƒ½é…ç½®
	features := DefaultAdvancedFeatures()

	// åˆ›å»ºå¢å¼ºå®¢æˆ·ç«¯
	enhanced := NewEnhancedLLMClient(llmClient, features)

	ctx := context.Background()

	// 1. æ¼”ç¤ºå“åº”ç¼“å­˜
	fmt.Println("\nğŸ“¦ 1. å“åº”ç¼“å­˜æ¼”ç¤º")
	fmt.Println(strings.Repeat("-", 80))

	req := &llm.CompletionRequest{
		Messages: []llm.Message{
			{Role: "user", Content: "ä»€ä¹ˆæ˜¯ Go è¯­è¨€ï¼Ÿ"},
		},
	}

	start := time.Now()
	resp1, err := enhanced.Complete(ctx, req)
	duration1 := time.Since(start)
	if err != nil {
		log.Printf("ç¬¬ä¸€æ¬¡è¯·æ±‚å¤±è´¥: %v", err)
	} else {
		fmt.Printf("ç¬¬ä¸€æ¬¡è¯·æ±‚è€—æ—¶: %v\n", duration1)
		fmt.Printf("å“åº”: %s\n", truncate(resp1.Content, 100))
	}

	// ç¬¬äºŒæ¬¡è¯·æ±‚åº”è¯¥å‘½ä¸­ç¼“å­˜
	start = time.Now()
	_, err = enhanced.Complete(ctx, req)
	duration2 := time.Since(start)
	if err != nil {
		log.Printf("ç¬¬äºŒæ¬¡è¯·æ±‚å¤±è´¥: %v", err)
	} else {
		fmt.Printf("ç¬¬äºŒæ¬¡è¯·æ±‚è€—æ—¶: %v (ç¼“å­˜å‘½ä¸­)\n", duration2)
		fmt.Printf("åŠ é€Ÿæ¯”: %.2fx\n", float64(duration1)/float64(duration2))
	}

	// 2. æ¼”ç¤º Tool Calling
	fmt.Println("\nğŸ”§ 2. Tool Calling æ¼”ç¤º")
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("å·²æ³¨å†Œå·¥å…·:\n")
	for i, tool := range features.Tools {
		fmt.Printf("  %d. %s: %s\n", i+1, tool.Function.Name, tool.Function.Description)
	}

	// 3. æ¼”ç¤ºå¤šæ¨¡æ€å¤„ç†
	fmt.Println("\nğŸ¨ 3. å¤šæ¨¡æ€æ”¯æŒæ¼”ç¤º")
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("æ”¯æŒçš„æ¨¡å¼: %v\n", features.SupportedModes)

	codeReq := &llm.CompletionRequest{
		Messages: []llm.Message{
			{Role: "user", Content: "åˆ†æè¿™æ®µä»£ç :\nfunc main() {\n    fmt.Println(\"Hello\")\n}"},
		},
	}
	_, err = enhanced.Complete(ctx, codeReq)
	if err != nil {
		log.Printf("ä»£ç åˆ†æå¤±è´¥: %v", err)
	}

	// 4. æ¼”ç¤ºè‡ªåŠ¨ Fallback
	fmt.Println("\nâš¡ 4. è‡ªåŠ¨ Fallback æ¼”ç¤º")
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("é…ç½®:\n")
	fmt.Printf("  - ä¸»æä¾›å•†: %s\n", "DeepSeek")
	fmt.Printf("  - Fallback æä¾›å•†: %v\n", features.FallbackProviders)
	fmt.Printf("  - æœ€å¤§é‡è¯•æ¬¡æ•°: %d\n", features.MaxRetries)

	fmt.Println("\nâœ… é«˜çº§åŠŸèƒ½æ¼”ç¤ºå®Œæˆ")
	fmt.Println(strings.Repeat("=", 80))
}

// truncate æˆªæ–­å­—ç¬¦ä¸²
func truncate(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}
