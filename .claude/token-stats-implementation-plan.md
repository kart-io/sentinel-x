# Token ç»Ÿè®¡åŠŸèƒ½å®æ–½è®¡åˆ’

ç”Ÿæˆæ—¶é—´: 2026-01-08 16:53

## ğŸ“‹ è®¡åˆ’æ¦‚è¿°

**ç›®æ ‡**: å®ç° LLM è°ƒç”¨çš„ Token ä½¿ç”¨ç»Ÿè®¡åŠŸèƒ½ï¼Œå‡†ç¡®è®°å½•æ¯æ¬¡è°ƒç”¨çš„ token æ¶ˆè€—ã€‚

**ä¼˜å…ˆçº§**: ğŸ”¥ é«˜ï¼ˆP0 - æœ¬å‘¨å¿…é¡»å®Œæˆï¼‰

**é¢„ä¼°å·¥ä½œé‡**: 6 å°æ—¶

**ç ´åæ€§å˜æ›´**: æ˜¯ï¼ˆéœ€è¦ä¿®æ”¹æ¥å£ç­¾åï¼‰

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. æ•°æ®ç»“æ„è®¾è®¡

```go
// pkg/llm/provider.go

// TokenUsage Token ä½¿ç”¨ç»Ÿè®¡
type TokenUsage struct {
    PromptTokens     int // æç¤ºè¯ token æ•°é‡
    CompletionTokens int // ç”Ÿæˆå†…å®¹ token æ•°é‡
    TotalTokens      int // æ€» token æ•°é‡
}

// GenerateResponse LLM ç”Ÿæˆå“åº”
type GenerateResponse struct {
    Content    string      // ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    TokenUsage *TokenUsage // Token ä½¿ç”¨ç»Ÿè®¡ï¼ˆå¯èƒ½ä¸º nilï¼‰
}
```

### 2. æ¥å£å˜æ›´ç­–ç•¥

**ç­–ç•¥**: ç ´åæ€§å˜æ›´ï¼ˆç›´æ¥ä¿®æ”¹æ¥å£ï¼‰

**ç†ç”±**:
- é¡¹ç›®å¤„äºæ—©æœŸé˜¶æ®µï¼Œå‘åå…¼å®¹æ€§ä¸æ˜¯é¦–è¦è€ƒè™‘
- æ¸…æ™°çš„æ¥å£æ¯”å…¼å®¹æ€§åŒ…è¢±æ›´é‡è¦
- æ‰€æœ‰è°ƒç”¨æ–¹éƒ½åœ¨é¡¹ç›®å†…éƒ¨ï¼Œå¯æ§

**å˜æ›´èŒƒå›´**:
```go
// ä¿®æ”¹å‰
type ChatProvider interface {
    Chat(ctx context.Context, messages []Message) (string, error)
    Generate(ctx context.Context, prompt string, systemPrompt string) (string, error)
    Name() string
}

// ä¿®æ”¹å
type ChatProvider interface {
    Chat(ctx context.Context, messages []Message) (*GenerateResponse, error)
    Generate(ctx context.Context, prompt string, systemPrompt string) (*GenerateResponse, error)
    Name() string
}
```

### 3. é”™è¯¯å¤„ç†ç­–ç•¥

- TokenUsage å­—æ®µå¯ä»¥ä¸º `nil`ï¼ˆå…¼å®¹ä¸æ”¯æŒ token ç»Ÿè®¡çš„æä¾›å•†ï¼‰
- ä¸Šå±‚ä»£ç å¿…é¡»æ£€æŸ¥ `nil` é¿å… panic
- å¦‚æœæä¾›å•†ä¸è¿”å› token ä¿¡æ¯ï¼Œä½¿ç”¨ 0 ä½œä¸ºé»˜è®¤å€¼

---

## ğŸ“ å®æ–½æ­¥éª¤

### æ­¥éª¤ 1: å®šä¹‰æ•°æ®ç»“æ„ (15 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/provider.go`

**ä¿®æ”¹å†…å®¹**:
```go
// åœ¨ Message ç»“æ„ä½“åæ·»åŠ 

// TokenUsage Token ä½¿ç”¨ç»Ÿè®¡
type TokenUsage struct {
    PromptTokens     int
    CompletionTokens int
    TotalTokens      int
}

// GenerateResponse LLM ç”Ÿæˆå“åº”
type GenerateResponse struct {
    Content    string
    TokenUsage *TokenUsage
}
```

**ä¾èµ–**: æ— 

**éªŒè¯**: ä»£ç ç¼–è¯‘é€šè¿‡

---

### æ­¥éª¤ 2: æ›´æ–° ChatProvider æ¥å£ (15 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/provider.go`

**ä¿®æ”¹å†…å®¹**:
```go
// ChatProvider å®šä¹‰ Chat ä¾›åº”å•†æ¥å£ã€‚
type ChatProvider interface {
    // Chat è¿›è¡Œå¤šè½®å¯¹è¯ã€‚
    Chat(ctx context.Context, messages []Message) (*GenerateResponse, error)

    // Generate æ ¹æ®æç¤ºç”Ÿæˆæ–‡æœ¬ï¼ˆå•è½®ï¼‰ã€‚
    Generate(ctx context.Context, prompt string, systemPrompt string) (*GenerateResponse, error)

    // Name è¿”å›ä¾›åº”å•†åç§°ã€‚
    Name() string
}
```

**ä¾èµ–**: æ­¥éª¤ 1

**å½±å“**: æ‰€æœ‰å®ç° ChatProvider çš„ä»£ç å°†ç¼–è¯‘å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰

**éªŒè¯**: è¿è¡Œ `go build ./...` æŸ¥çœ‹ç¼–è¯‘é”™è¯¯

---

### æ­¥éª¤ 3: æ›´æ–° Generator (30 åˆ†é’Ÿ)

**æ–‡ä»¶**: `internal/rag/biz/generator.go`

**ä¿®æ”¹å†…å®¹**:
```go
// GenerateAnswer æ ¹æ®æ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆã€‚
func (g *Generator) GenerateAnswer(ctx context.Context, question string, results []*store.SearchResult) (*GenerateResponse, error) {
    if len(results) == 0 {
        return &GenerateResponse{
            Content:    "I couldn't find any relevant information in the knowledge base.",
            TokenUsage: nil,
        }, nil
    }

    // æ£€æŸ¥ context æ˜¯å¦å·²å–æ¶ˆ
    if ctx.Err() != nil {
        return nil, fmt.Errorf("context cancelled before generation: %w", ctx.Err())
    }

    // æ„å»ºä¸Šä¸‹æ–‡
    var contextBuilder strings.Builder
    for i, result := range results {
        contextBuilder.WriteString(fmt.Sprintf("[%d] From %s - %s:\n%s\n\n",
            i+1, result.DocumentName, result.Section, result.Content))
    }

    // ç”Ÿæˆæç¤ºè¯
    prompt := strings.ReplaceAll(g.config.SystemPrompt, "{{context}}", contextBuilder.String())
    prompt = strings.ReplaceAll(prompt, "{{question}}", question)

    // è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ
    logger.Info("Calling LLM to generate answer...")
    resp, err := g.chatProvider.Generate(ctx, prompt, "")
    if err != nil {
        logger.Errorf("LLM generation failed: %v", err)
        return nil, fmt.Errorf("failed to generate answer: %w", err)
    }

    if resp.TokenUsage != nil {
        logger.Infof("LLM answer generated (length: %d, tokens: %d)",
            len(resp.Content), resp.TokenUsage.TotalTokens)
    } else {
        logger.Infof("LLM answer generated (length: %d)", len(resp.Content))
    }

    return resp, nil
}
```

**ä¾èµ–**: æ­¥éª¤ 2

**éªŒè¯**: ç¼–è¯‘é€šè¿‡ï¼Œé€»è¾‘æ­£ç¡®

---

### æ­¥éª¤ 4: æ›´æ–° RAGService (30 åˆ†é’Ÿ)

**æ–‡ä»¶**: `internal/rag/biz/service.go`

**ä¿®æ”¹å†…å®¹**:
```go
// 3. ç”Ÿæˆç­”æ¡ˆ
llmStart := time.Now()
resp, err := s.generator.GenerateAnswer(ctx, question, retrievalResult.Results)
llmDuration := time.Since(llmStart)

// ä»å“åº”ä¸­è·å– token ä½¿ç”¨ä¿¡æ¯
promptTokens := 0
completionTokens := 0
if resp != nil && resp.TokenUsage != nil {
    promptTokens = resp.TokenUsage.PromptTokens
    completionTokens = resp.TokenUsage.CompletionTokens
}
s.metrics.RecordLLMCall(llmDuration, promptTokens, completionTokens, err)

if err != nil {
    queryErr = err
    return nil, err
}

// 4. æ„å»ºå“åº”
sources := make([]model.ChunkSource, len(retrievalResult.Results))
for i, result := range retrievalResult.Results {
    sources[i] = model.ChunkSource{
        DocumentID:   result.DocumentID,
        DocumentName: result.DocumentName,
        Section:      result.Section,
        Content:      result.Content,
        Score:        result.Score,
    }
}

queryResult := &model.QueryResult{
    Answer:  resp.Content,  // ä½¿ç”¨ resp.Content è€Œä¸æ˜¯ answer
    Sources: sources,
}
```

**ä¾èµ–**: æ­¥éª¤ 3

**éªŒè¯**: ç¼–è¯‘é€šè¿‡ï¼Œé€»è¾‘æ­£ç¡®

---

### æ­¥éª¤ 5: æ›´æ–° LLM æä¾›å•†å®ç° (3 å°æ—¶)

#### 5.1 OpenAI Provider (45 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/openai/provider.go`

**ä¿®æ”¹å†…å®¹**:
- æ›´æ–° `Generate` æ–¹æ³•è¿”å› `*llm.GenerateResponse`
- ä» OpenAI API å“åº”ä¸­æå– token ä¿¡æ¯
- å¡«å…… TokenUsage ç»“æ„

**ä»£ç ç¤ºä¾‹**:
```go
func (p *OpenAIProvider) Generate(ctx context.Context, prompt string, systemPrompt string) (*llm.GenerateResponse, error) {
    // ... æ„å»ºè¯·æ±‚ ...

    // è°ƒç”¨ OpenAI API
    resp, err := p.client.CreateChatCompletion(ctx, req)
    if err != nil {
        return nil, err
    }

    if len(resp.Choices) == 0 {
        return nil, fmt.Errorf("no response from OpenAI")
    }

    return &llm.GenerateResponse{
        Content: resp.Choices[0].Message.Content,
        TokenUsage: &llm.TokenUsage{
            PromptTokens:     resp.Usage.PromptTokens,
            CompletionTokens: resp.Usage.CompletionTokens,
            TotalTokens:      resp.Usage.TotalTokens,
        },
    }, nil
}
```

#### 5.2 DeepSeek Provider (45 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/deepseek/provider.go`

**ä¿®æ”¹å†…å®¹**: ç±»ä¼¼ OpenAIï¼Œä» API å“åº”ä¸­æå– token ä¿¡æ¯

#### 5.3 SiliconFlow Provider (45 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/siliconflow/provider.go`

**ä¿®æ”¹å†…å®¹**: ç±»ä¼¼ OpenAIï¼Œä» API å“åº”ä¸­æå– token ä¿¡æ¯

#### 5.4 Ollama Provider (30 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/ollama/provider.go`

**ä¿®æ”¹å†…å®¹**:
- Ollama å¯èƒ½ä¸è¿”å› token ä¿¡æ¯
- ä½¿ç”¨ç®€å•ä¼°ç®—æˆ–è¿”å› `nil`

**ä»£ç ç¤ºä¾‹**:
```go
return &llm.GenerateResponse{
    Content:    answer,
    TokenUsage: nil, // Ollama ä¸æä¾› token ç»Ÿè®¡
}, nil
```

#### 5.5 Gemini Provider (30 åˆ†é’Ÿ)

**æ–‡ä»¶**: `pkg/llm/gemini/provider.go`

**ä¿®æ”¹å†…å®¹**: ä» Gemini API å“åº”ä¸­æå– token ä¿¡æ¯

---

### æ­¥éª¤ 6: æ›´æ–°æµ‹è¯• (1 å°æ—¶)

#### 6.1 æ›´æ–° Provider æµ‹è¯•

**æ–‡ä»¶**: `pkg/llm/provider_test.go`

**ä¿®æ”¹å†…å®¹**:
- æ›´æ–° mock è¿”å›å€¼ä¸º `*GenerateResponse`
- éªŒè¯ TokenUsage å­—æ®µ

#### 6.2 æ›´æ–° Generator æµ‹è¯•

**æ–‡ä»¶**: `internal/rag/biz/generator_test.go` (å¦‚æœå­˜åœ¨)

**ä¿®æ”¹å†…å®¹**:
- æ›´æ–°æ–­è¨€æ£€æŸ¥ `*GenerateResponse`
- æµ‹è¯• TokenUsage ä¸º nil çš„æƒ…å†µ

#### 6.3 æ›´æ–° RAGService æµ‹è¯•

**æ–‡ä»¶**: `internal/rag/biz/service_test.go` (å¦‚æœå­˜åœ¨)

**ä¿®æ”¹å†…å®¹**:
- Mock Generator è¿”å›å¸¦ TokenUsage çš„å“åº”
- éªŒè¯ metrics è®°å½•æ­£ç¡®

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] æ‰€æœ‰ LLM æä¾›å•†å®ç°å·²æ›´æ–°
- [ ] OpenAIã€DeepSeekã€SiliconFlow è¿”å›çœŸå® token ç»Ÿè®¡
- [ ] Ollamaã€Gemini è‡³å°‘è¿”å›æœ‰æ•ˆçš„å“åº”ï¼ˆTokenUsage å¯ä¸º nilï¼‰
- [ ] RAG Service æ­£ç¡®è®°å½• token ä½¿ç”¨åˆ° metrics
- [ ] ç¼“å­˜çš„å“åº”ä¹ŸåŒ…å« token ä¿¡æ¯ï¼ˆå¦‚æœåŸå§‹å“åº”æœ‰ï¼‰

### æŠ€æœ¯éªŒæ”¶
- [ ] æ‰€æœ‰ä»£ç ç¼–è¯‘é€šè¿‡ (`go build ./...`)
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ (`go test ./...`)
- [ ] æ²¡æœ‰å¼•å…¥æ•°æ®ç«äº‰ (`go test -race ./...`)
- [ ] ä»£ç æ ¼å¼åŒ–æ­£ç¡® (`go fmt ./...`)

### è´¨é‡éªŒæ”¶
- [ ] æ‰€æœ‰æ³¨é‡Šä½¿ç”¨ç®€ä½“ä¸­æ–‡
- [ ] é”™è¯¯å¤„ç†å®Œå–„ï¼ˆæ£€æŸ¥ nilï¼‰
- [ ] æ—¥å¿—è®°å½•æ¸…æ™°
- [ ] æ— æ˜æ˜¾æ€§èƒ½é€€åŒ–

---

## âš ï¸ é£é™©è¯„ä¼°

### é«˜é£é™©
1. **ç ´åæ€§å˜æ›´**: ä¿®æ”¹æ¥å£ç­¾åä¼šå¯¼è‡´æ‰€æœ‰å®ç°å’Œè°ƒç”¨æ–¹ç¼–è¯‘å¤±è´¥
   - **ç¼“è§£**: ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä¿®æ”¹ï¼Œç¡®ä¿ç¼–è¯‘é€šè¿‡åå†æäº¤

2. **API å·®å¼‚**: ä¸åŒ LLM æä¾›å•†è¿”å›çš„ token ä¿¡æ¯æ ¼å¼ä¸åŒ
   - **ç¼“è§£**: ç»Ÿä¸€æ˜ å°„åˆ° TokenUsage ç»“æ„ï¼Œæä¾›æ¸…æ™°çš„æ–‡æ¡£

### ä¸­é£é™©
3. **æµ‹è¯•è¦†ç›–ä¸è¶³**: å¯èƒ½é—æ¼æŸäº›è¾¹ç•Œæƒ…å†µ
   - **ç¼“è§£**: ç¼–å†™å…¨é¢çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

4. **æ€§èƒ½å½±å“**: å¢åŠ ç»“æ„ä½“å­—æ®µå¯èƒ½å½±å“æ€§èƒ½
   - **ç¼“è§£**: ä½¿ç”¨æŒ‡é’ˆé¿å…ä¸å¿…è¦çš„æ‹·è´ï¼Œè¿›è¡Œæ€§èƒ½æµ‹è¯•

### ä½é£é™©
5. **å‘åå…¼å®¹æ€§**: æ—§ä»£ç æ— æ³•ä½¿ç”¨
   - **ç¼“è§£**: é¡¹ç›®å†…éƒ¨æ§åˆ¶ï¼Œå¯æ¥å—

---

## ğŸ”„ å›æ»šç­–ç•¥

å¦‚æœå®æ–½è¿‡ç¨‹ä¸­é‡åˆ°é‡å¤§é—®é¢˜ï¼š

1. **å¿«é€Ÿå›æ»š**: ä½¿ç”¨ `git revert` å›æ»šæäº¤
2. **æ•°æ®ä¿æŠ¤**: token ç»Ÿè®¡æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¸å½±å“ç°æœ‰æ•°æ®
3. **æœåŠ¡å¯ç”¨æ€§**: ä¸å½±å“æœåŠ¡æ­£å¸¸è¿è¡Œï¼Œåªæ˜¯æŒ‡æ ‡ä¸å‡†ç¡®

---

## ğŸ“Š å·¥ä½œé‡åˆ†é…

| æ­¥éª¤ | å·¥ä½œé‡ | å…³é”®è·¯å¾„ |
|------|--------|----------|
| 1. å®šä¹‰æ•°æ®ç»“æ„ | 15 åˆ†é’Ÿ | âœ… |
| 2. æ›´æ–°æ¥å£ | 15 åˆ†é’Ÿ | âœ… |
| 3. æ›´æ–° Generator | 30 åˆ†é’Ÿ | âœ… |
| 4. æ›´æ–° RAGService | 30 åˆ†é’Ÿ | âœ… |
| 5. æ›´æ–°æä¾›å•† | 3 å°æ—¶ | âœ… |
| 6. æ›´æ–°æµ‹è¯• | 1 å°æ—¶ | âœ… |
| **æ€»è®¡** | **6 å°æ—¶** | |

---

## ğŸ“‹ æ‰§è¡Œæ£€æŸ¥æ¸…å•

### å‡†å¤‡é˜¶æ®µ
- [x] åˆ¶å®šå®æ–½è®¡åˆ’
- [ ] å®¡æŸ¥è®¡åˆ’å¯è¡Œæ€§
- [ ] ç¡®è®¤å·¥ä½œç¯å¢ƒå°±ç»ª

### å®æ–½é˜¶æ®µ
- [ ] æ­¥éª¤ 1: å®šä¹‰æ•°æ®ç»“æ„
- [ ] æ­¥éª¤ 2: æ›´æ–°æ¥å£
- [ ] æ­¥éª¤ 3: æ›´æ–° Generator
- [ ] æ­¥éª¤ 4: æ›´æ–° RAGService
- [ ] æ­¥éª¤ 5.1: æ›´æ–° OpenAI Provider
- [ ] æ­¥éª¤ 5.2: æ›´æ–° DeepSeek Provider
- [ ] æ­¥éª¤ 5.3: æ›´æ–° SiliconFlow Provider
- [ ] æ­¥éª¤ 5.4: æ›´æ–° Ollama Provider
- [ ] æ­¥éª¤ 5.5: æ›´æ–° Gemini Provider
- [ ] æ­¥éª¤ 6: æ›´æ–°æµ‹è¯•

### éªŒè¯é˜¶æ®µ
- [ ] ç¼–è¯‘éªŒè¯
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] ä»£ç å®¡æŸ¥

### å®Œæˆé˜¶æ®µ
- [ ] æäº¤ä»£ç 
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] é€šçŸ¥ç›¸å…³æ–¹

---

**è®¡åˆ’åˆ¶å®šæ—¶é—´**: 2026-01-08 16:53
**è®¡åˆ’å®¡æŸ¥äºº**: Claude Code
**é¢„è®¡å¼€å§‹æ—¶é—´**: 2026-01-08 17:00
**é¢„è®¡å®Œæˆæ—¶é—´**: 2026-01-08 23:00

---

*æœ¬è®¡åˆ’å°†æŒ‡å¯¼ Token ç»Ÿè®¡åŠŸèƒ½çš„å®Œæ•´å®æ–½è¿‡ç¨‹*
