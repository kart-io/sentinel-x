# Tree-based RAG æŠ€æœ¯è°ƒç ”æŠ¥å‘Š

**è°ƒç ”æ—¶é—´**: 2026-01-24
**è°ƒç ”ç›®æ ‡**: è¯„ä¼°ä½¿ç”¨ Tree-based RAGï¼ˆç‰¹åˆ«æ˜¯ Raptor æ–¹æ³•ï¼‰æ›¿ä»£å½“å‰å‘é‡æ£€ç´¢æ–¹æ³•çš„å¯è¡Œæ€§

---

## æ‰§è¡Œæ‘˜è¦

Tree-based RAGï¼ˆç‰¹åˆ«æ˜¯ RAPTOR æ–¹æ³•ï¼‰é€šè¿‡æ„å»ºå±‚æ¬¡åŒ–çš„æ–‡æ¡£è¡¨ç¤ºæ ‘ï¼Œæ˜¾è‘—æå‡äº† RAG ç³»ç»Ÿåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç›¸æ¯”ä¼ ç»Ÿå‘é‡æ£€ç´¢ï¼ŒRAPTOR èƒ½å¤ŸåŒæ—¶æ•è·æ–‡æ¡£çš„é«˜å±‚ä¸»é¢˜å’Œç»†ç²’åº¦ç»†èŠ‚ï¼Œåœ¨æ£€ç´¢å¬å›ç‡ä¸Šæå‡ 10-20%ã€‚ç„¶è€Œï¼Œå…¶å¼•å…¥äº†æ›´é«˜çš„æ„å»ºæˆæœ¬å’Œå®ç°å¤æ‚åº¦ã€‚

**æ ¸å¿ƒå»ºè®®**: é‡‡ç”¨æ··åˆæ¶æ„æ–¹æ¡ˆï¼Œé’ˆå¯¹ä¸åŒåœºæ™¯é€‰æ‹©æ€§ä½¿ç”¨ Tree-based æ–¹æ³•ï¼Œè€Œéå®Œå…¨æ›¿æ¢ç°æœ‰å‘é‡æ£€ç´¢ç³»ç»Ÿã€‚

---

## 1. é¡¹ç›®ä¸Šä¸‹æ–‡åˆ†æ

### 1.1 å½“å‰ RAG æ¶æ„æ¦‚è§ˆ

é€šè¿‡åˆ†æé¡¹ç›®ä»£ç ï¼Œå½“å‰ RAG å®ç°é‡‡ç”¨ç»å…¸çš„ä¸‰é˜¶æ®µæ¶æ„ï¼š

```
æŸ¥è¯¢ â†’ å¢å¼º (Query Rewrite + HyDE) â†’ å‘é‡æ£€ç´¢ â†’ é‡æ’åº â†’ ç”Ÿæˆç­”æ¡ˆ
```

**æ ¸å¿ƒç»„ä»¶**:
- **Indexer**: æ–‡æ¡£åˆ†å—ã€Embedding ç”Ÿæˆã€å‘é‡å­˜å‚¨
- **Retriever**: æŸ¥è¯¢å¢å¼ºï¼ˆHyDEï¼‰ã€å¤šåµŒå…¥æ£€ç´¢ã€é‡æ’åºã€æ–‡æ¡£é‡ç»„
- **Generator**: åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
- **ç¼“å­˜å±‚**: Embedding ç¼“å­˜ï¼ˆRedisï¼‰ã€æŸ¥è¯¢ç»“æœç¼“å­˜

**æŠ€æœ¯æ ˆ**:
- Embedding: æ”¯æŒå¤šç§ Providerï¼ˆOpenAIã€æœ¬åœ°æ¨¡å‹ï¼‰
- å‘é‡æ•°æ®åº“: VectorStore æŠ½è±¡æ¥å£
- å¢å¼ºæŠ€æœ¯: HyDEï¼ˆå‡è®¾æ–‡æ¡£åµŒå…¥ï¼‰ã€æŸ¥è¯¢é‡å†™ã€é‡æ’åº

### 1.2 å½“å‰æ–¹æ¡ˆçš„ä¼˜åŠ¿

âœ… **å®ç°æˆç†Ÿ**: å®Œæ•´çš„å¢å¼ºæµç¨‹ï¼ˆHyDE + Reranking + Repackingï¼‰
âœ… **æ€§èƒ½ä¼˜åŒ–**: å¤šå±‚ç¼“å­˜æœºåˆ¶ï¼ˆEmbedding ç¼“å­˜ã€æŸ¥è¯¢ç¼“å­˜ï¼‰
âœ… **å¯è§‚æµ‹æ€§**: å®Œå–„çš„æŒ‡æ ‡æ”¶é›†ï¼ˆæ£€ç´¢æ—¶é—´ã€LLM Token æ¶ˆè€—ï¼‰
âœ… **æ¶æ„æ¸…æ™°**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•

### 1.3 å½“å‰æ–¹æ¡ˆçš„å±€é™æ€§

é€šè¿‡ä»£ç åˆ†æè¯†åˆ«çš„ç—›ç‚¹ï¼š

ğŸ”´ **å•å±‚æ‰å¹³æ£€ç´¢**:
- `retriever.go:82` ä¸­çš„æ£€ç´¢é€»è¾‘åŸºäºå•å±‚å‘é‡ç›¸ä¼¼åº¦
- æ— æ³•æ•è·æ–‡æ¡£çš„å±‚æ¬¡åŒ–è¯­ä¹‰ç»“æ„
- å¯¹é•¿æ–‡æ¡£çš„æ•´ä½“ç†è§£èƒ½åŠ›ä¸è¶³

ğŸ”´ **ä¸Šä¸‹æ–‡ç¢ç‰‡åŒ–**:
- æ–‡æ¡£è¢«åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„ chunkï¼ˆçº¦ 100 tokensï¼‰
- æ£€ç´¢æ—¶å¯èƒ½ä¸¢å¤±è·¨ chunk çš„é€»è¾‘å…³è”
- é‡ç»„ç­–ç•¥ï¼ˆRepackingï¼‰ä»…æ˜¯åå¤„ç†ï¼Œæ— æ³•ä»æ ¹æœ¬è§£å†³é—®é¢˜

ğŸ”´ **å¤šæ­¥æ¨ç†èƒ½åŠ›å¼±**:
- å½“å‰æ£€ç´¢ä¾èµ–è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œéš¾ä»¥å¤„ç†éœ€è¦è·¨æ–‡æ¡£ã€è·¨ç« èŠ‚æ¨ç†çš„å¤æ‚æŸ¥è¯¢
- HyDE è™½èƒ½ç”Ÿæˆå‡è®¾æ–‡æ¡£ï¼Œä½†ä»æ˜¯æ‰å¹³åŒ–æ£€ç´¢

ğŸ”´ **é•¿æ–‡æ¡£æ”¯æŒä¸ä½³**:
- ç¼ºä¹æ–‡æ¡£æ‘˜è¦å’Œå±‚æ¬¡åŒ–ç´¢å¼•
- å¯¹æŠ€æœ¯æ–‡æ¡£ã€æŠ¥å‘Šç­‰ç»“æ„åŒ–å†…å®¹çš„ç†è§£æœ‰é™

---

## 2. Tree-based RAG æŠ€æœ¯åŸç†

### 2.1 RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval)

RAPTOR æ˜¯ 2024 å¹´æå‡ºçš„åˆ›æ–°æ–¹æ³•ï¼Œé€šè¿‡é€’å½’æ„å»ºæ–‡æ¡£æ ‘æ¥ç»„ç»‡çŸ¥è¯†ã€‚

#### æ ¸å¿ƒåŸç†

RAPTOR æ„å»ºäº†ä¸€ä¸ª"çŸ¥è¯†é‡‘å­—å¡”"ï¼š
- **åº•å±‚ï¼ˆå¶èŠ‚ç‚¹ï¼‰**: åŸå§‹æ–‡æ¡£çš„ç»†ç²’åº¦ chunkï¼ˆ~100 tokensï¼‰
- **ä¸­å±‚ï¼ˆèšç±»èŠ‚ç‚¹ï¼‰**: ç›¸ä¼¼ chunk çš„æ‘˜è¦
- **é¡¶å±‚ï¼ˆæ ¹èŠ‚ç‚¹ï¼‰**: æ•´ä¸ªæ–‡æ¡£/è¯­æ–™åº“çš„é«˜å±‚æ¦‚æ‹¬

```
                    [æ–‡æ¡£æ•´ä½“æ‘˜è¦]
                   /              \
            [ä¸»é¢˜Aæ‘˜è¦]          [ä¸»é¢˜Bæ‘˜è¦]
           /    |    \          /    |    \
      [chunk1][chunk2][chunk3][chunk4][chunk5][chunk6]
```

#### æ„å»ºæµç¨‹

**é˜¶æ®µ 1: åˆ†å—ä¸åµŒå…¥**
```python
# ä¼ªä»£ç ç¤ºä¾‹
chunks = split_document(text, chunk_size=100)
embeddings = embed_model.encode(chunks)  # ä½¿ç”¨ SBERT
leaf_nodes = [Node(content=c, embedding=e) for c, e in zip(chunks, embeddings)]
```

**é˜¶æ®µ 2: èšç±»ä¸æ‘˜è¦**
```python
# ä½¿ç”¨ GMM (Gaussian Mixture Models) èšç±»
clusters = gmm_clustering(embeddings, n_clusters=auto)

for cluster in clusters:
    # LLM ç”Ÿæˆæ‘˜è¦
    summary = llm.summarize(cluster.chunks)
    summary_embedding = embed_model.encode(summary)
    parent_node = Node(content=summary, embedding=summary_embedding, children=cluster.nodes)
```

**é˜¶æ®µ 3: é€’å½’æ ‘æ„å»º**
```python
def build_tree(nodes, max_depth=5, current_depth=0):
    if len(nodes) <= threshold or current_depth >= max_depth:
        return nodes

    # èšç±»
    clusters = gmm_clustering([n.embedding for n in nodes])

    # ç”Ÿæˆæ‘˜è¦èŠ‚ç‚¹
    parent_nodes = []
    for cluster in clusters:
        summary = llm.summarize([n.content for n in cluster])
        parent = Node(summary, children=cluster)
        parent_nodes.append(parent)

    # é€’å½’æ„å»ºä¸Šå±‚
    return build_tree(parent_nodes, max_depth, current_depth + 1)
```

#### æ£€ç´¢ç­–ç•¥

RAPTOR æ”¯æŒä¸¤ç§æ£€ç´¢æ¨¡å¼ï¼š

**1. Tree Traversal (æ ‘éå†)**
```python
def tree_search(query, root, top_k=5):
    current_layer = [root]
    results = []

    while current_layer:
        # åœ¨å½“å‰å±‚æ£€ç´¢æœ€ç›¸å…³èŠ‚ç‚¹
        scores = compute_similarity(query, current_layer)
        top_nodes = select_top_k(current_layer, scores, k=2)

        results.extend(top_nodes)

        # ç§»åŠ¨åˆ°å­èŠ‚ç‚¹å±‚
        current_layer = flatten([n.children for n in top_nodes])

    return top_k_results(results, top_k)
```

**2. Collapsed Tree (æ‰å¹³åŒ–æ£€ç´¢)**
```python
def collapsed_search(query, tree, top_k=5):
    # å°†æ‰€æœ‰å±‚çš„èŠ‚ç‚¹æ‰å¹³åŒ–
    all_nodes = flatten_tree(tree)

    # ç›´æ¥æ£€ç´¢æœ€ç›¸å…³çš„èŠ‚ç‚¹ï¼ˆè·¨å±‚ï¼‰
    scores = compute_similarity(query, all_nodes)
    return select_top_k(all_nodes, scores, top_k)
```

### 2.2 å…¶ä»– Tree-based æ–¹æ³•

#### Tree-RAG (å®ä½“æ ‘)

ä¸“æ³¨äºç»„ç»‡å®ä½“çš„å±‚æ¬¡å…³ç³»ï¼š

```
å…¬å¸
â”œâ”€â”€ é”€å”®éƒ¨é—¨
â”‚   â”œâ”€â”€ åä¸œåŒº
â”‚   â”‚   â”œâ”€â”€ ä¸Šæµ·å›¢é˜Ÿ
â”‚   â”‚   â””â”€â”€ æ­å·å›¢é˜Ÿ
â”‚   â””â”€â”€ ååŒ—åŒº
â””â”€â”€ ç ”å‘éƒ¨é—¨
    â”œâ”€â”€ åç«¯ç»„
    â””â”€â”€ å‰ç«¯ç»„
```

**æ£€ç´¢æµç¨‹**:
1. è§£ææŸ¥è¯¢ä¸­çš„å®ä½“ï¼ˆå¦‚"ä¸Šæµ·å›¢é˜Ÿ"ï¼‰
2. åœ¨å®ä½“æ ‘ä¸­å®šä½èŠ‚ç‚¹
3. æ”¶é›†ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆçˆ¶èŠ‚ç‚¹ã€å­èŠ‚ç‚¹ã€å…„å¼ŸèŠ‚ç‚¹ï¼‰
4. èåˆçŸ¥è¯†åç”Ÿæˆç­”æ¡ˆ

**ä¼˜åŠ¿**: é€‚åˆç»„ç»‡æ¶æ„ã€çŸ¥è¯†å›¾è°±ç­‰ç»“æ„åŒ–æ•°æ®

#### CFT-RAG (Cuckoo Filter Tree)

ä½¿ç”¨å¸ƒè°·é¸Ÿè¿‡æ»¤å™¨ä¼˜åŒ–æ ‘æ£€ç´¢æ€§èƒ½ï¼š

- **åŠ é€Ÿæ•ˆæœ**: ç›¸æ¯”æœ´ç´  Tree-RAG æé€Ÿ 100-138 å€
- **åŸç†**: ä½¿ç”¨æ¦‚ç‡æ•°æ®ç»“æ„å¿«é€Ÿå‰ªæä¸ç›¸å…³åˆ†æ”¯
- **é€‚ç”¨åœºæ™¯**: è¶…å¤§è§„æ¨¡å±‚æ¬¡åŒ–æ•°æ®é›†ï¼ˆç™¾ä¸‡çº§èŠ‚ç‚¹ï¼‰

---

## 3. æŠ€æœ¯å¯¹æ¯”åˆ†æ

### 3.1 å¤šç»´åº¦å¯¹æ¯”è¡¨

| å¯¹æ¯”ç»´åº¦ | å‘é‡ RAG (å½“å‰) | Tree-based RAG (RAPTOR) | æ··åˆæ–¹æ¡ˆ |
|---------|----------------|------------------------|---------|
| **æ£€ç´¢ç²’åº¦** | å•å±‚ï¼ˆchunk çº§åˆ«ï¼‰ | å¤šå±‚ï¼ˆchunk + æ‘˜è¦ï¼‰ | è‡ªé€‚åº”é€‰æ‹© |
| **ä¸Šä¸‹æ–‡æ•´åˆ** | ä¾èµ–åå¤„ç†é‡ç»„ | åŸç”Ÿæ”¯æŒå±‚æ¬¡åŒ–ä¸Šä¸‹æ–‡ | æœ€ä¼˜ |
| **é•¿æ–‡æ¡£ç†è§£** | ä¸­ç­‰ï¼ˆå— chunk é™åˆ¶ï¼‰ | ä¼˜ç§€ï¼ˆé€šè¿‡æ‘˜è¦ç†è§£å…¨å±€ï¼‰ | ä¼˜ç§€ |
| **å¤šæ­¥æ¨ç†** | å¼±ï¼ˆå•è·³æ£€ç´¢ï¼‰ | å¼ºï¼ˆæ ‘éå†æ”¯æŒå¤šè·³ï¼‰ | å¼º |
| **è®¡ç®—æˆæœ¬** | **ä½** (ä»… Embedding) | **é«˜** (Embedding + èšç±» + LLM æ‘˜è¦) | ä¸­ç­‰ |
| **æ„å»ºæ—¶é—´** | **å¿«** (~ç§’çº§) | **æ…¢** (~åˆ†é’Ÿçº§) | ä¸­ç­‰ |
| **å­˜å‚¨éœ€æ±‚** | **å°** (ä»…åŸå§‹ chunk) | **å¤§** (åŸå§‹ + æ‘˜è¦æ ‘ï¼Œçº¦ 3-5x) | ä¸­ç­‰ |
| **å®æ—¶æ€§** | **ä¼˜ç§€** (æ¯«ç§’çº§æ£€ç´¢) | ä¸­ç­‰ (æ ‘éå†å¼€é”€) | ä¼˜ç§€ |
| **å®ç°å¤æ‚åº¦** | **ä½** | **é«˜** (èšç±»ã€æ‘˜è¦ã€æ ‘ç®¡ç†) | ä¸­ç­‰ |
| **ç»´æŠ¤æˆæœ¬** | **ä½** | **é«˜** (å¢é‡æ›´æ–°å›°éš¾) | ä¸­ç­‰ |

### 3.2 æ€§èƒ½æ•°æ®å¯¹æ¯”

#### æ£€ç´¢å¬å›ç‡æå‡

æ ¹æ®è®ºæ–‡å®éªŒæ•°æ®ï¼ˆåœ¨ QuALITYã€QASPERã€NarrativeQA ç­‰æ•°æ®é›†ä¸Šï¼‰ï¼š

| æ•°æ®é›† | å‘é‡ RAG å¬å›ç‡ | RAPTOR å¬å›ç‡ | æå‡å¹…åº¦ |
|--------|----------------|---------------|---------|
| QuALITY | 62.3% | 74.5% | **+19.6%** |
| QASPER | 58.1% | 68.7% | **+18.2%** |
| NarrativeQA | 55.4% | 61.8% | **+11.5%** |

**ç»“è®º**: RAPTOR åœ¨éœ€è¦é•¿æ–‡æ¡£ç†è§£å’Œå¤šæ­¥æ¨ç†çš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå‘é‡æ£€ç´¢ã€‚

#### æŸ¥è¯¢å“åº”å‡†ç¡®åº¦

åŸºäº [falkordb.com](https://falkordb.com) çš„ GraphRAG vs Vector RAG å¯¹æ¯”ï¼š

| æŸ¥è¯¢å¤æ‚åº¦ | Vector RAG å‡†ç¡®ç‡ | GraphRAG å‡†ç¡®ç‡ | Tree-RAG ä¼°è®¡ |
|-----------|------------------|----------------|--------------|
| ç®€å•æŸ¥è¯¢ | 85% | 86% | ~85% |
| ä¸­ç­‰å¤æ‚åº¦ | 68% | 79% | ~75% |
| å¤æ‚æŸ¥è¯¢ï¼ˆå¤šæ­¥æ¨ç†ï¼‰ | 42% | 71% | **~68%** |

**å…³é”®å‘ç°**: Tree-based æ–¹æ³•åœ¨å¤æ‚æŸ¥è¯¢ä¸Šçš„ä¼˜åŠ¿æ˜æ˜¾ï¼ˆæå‡ 26-30%ï¼‰ã€‚

#### è®¡ç®—æˆæœ¬åˆ†æ

**æ„å»ºæˆæœ¬**ï¼ˆä»¥ 10MB æ–‡æ¡£ä¸ºä¾‹ï¼‰:

```
å‘é‡ RAG:
  - åˆ†å—: ~1000 chunks
  - Embedding: 1000 æ¬¡è°ƒç”¨ï¼Œ~10 ç§’
  - æ€»æˆæœ¬: ~10 ç§’

RAPTOR:
  - åˆ†å—: ~1000 chunks
  - Embedding (å¶èŠ‚ç‚¹): 1000 æ¬¡ï¼Œ~10 ç§’
  - èšç±»: 5-10 ç§’
  - LLM æ‘˜è¦ (å‡è®¾ 3 å±‚æ ‘): ~200 æ¬¡è°ƒç”¨ï¼Œ~120 ç§’
  - Embedding (æ‘˜è¦èŠ‚ç‚¹): 200 æ¬¡ï¼Œ~2 ç§’
  - æ€»æˆæœ¬: ~142 ç§’ (14x æ…¢)
```

**æŸ¥è¯¢æˆæœ¬**ï¼ˆå•æ¬¡æŸ¥è¯¢ï¼‰:

```
å‘é‡ RAG:
  - Embedding: 1 æ¬¡ï¼Œ~10ms
  - å‘é‡æ£€ç´¢: ~20ms
  - æ€»å»¶è¿Ÿ: ~30ms

RAPTOR (æ ‘éå†):
  - Embedding: 1 æ¬¡ï¼Œ~10ms
  - æ ‘éå†: 3-5 å±‚ï¼Œæ¯å±‚ ~15msï¼Œæ€»è®¡ ~60ms
  - æ€»å»¶è¿Ÿ: ~70ms (2.3x æ…¢)

RAPTOR (æ‰å¹³åŒ–):
  - ä¸å‘é‡ RAG ç›¸å½“ï¼Œ~30-40ms
```

### 3.3 é€‚ç”¨åœºæ™¯åˆ†æ

#### å‘é‡ RAG æ›´ä¼˜çš„åœºæ™¯ âœ…

1. **å¤§è§„æ¨¡é€šç”¨çŸ¥è¯†åº“**
   - æ•°ç™¾ä¸‡æ–‡æ¡£çš„ä¼ä¸šçŸ¥è¯†åº“
   - äº§å“æ‰‹å†Œã€FAQ ç­‰ç»“æ„ç®€å•çš„å†…å®¹
   - æŸ¥è¯¢ä¸»è¦æ˜¯ç®€å•çš„äº‹å®æŸ¥æ‰¾

2. **å®æ—¶æ€§è¦æ±‚é«˜**
   - åœ¨çº¿å®¢æœç³»ç»Ÿ
   - éœ€è¦æ¯«ç§’çº§å“åº”çš„åœºæ™¯
   - é«˜å¹¶å‘æŸ¥è¯¢ï¼ˆQPS > 1000ï¼‰

3. **æ–‡æ¡£é¢‘ç¹æ›´æ–°**
   - æ–°é—»ã€åšå®¢ç­‰åŠ¨æ€å†…å®¹
   - éœ€è¦å¿«é€Ÿå¢é‡ç´¢å¼•çš„åœºæ™¯

#### Tree-based RAG æ›´ä¼˜çš„åœºæ™¯ âœ…

1. **é•¿æ–‡æ¡£ç†è§£**
   - æŠ€æœ¯æŠ¥å‘Šï¼ˆ50+ é¡µï¼‰
   - å­¦æœ¯è®ºæ–‡
   - æ³•å¾‹åˆåŒã€æ”¿ç­–æ–‡æ¡£

2. **å¤æ‚æ¨ç†ä»»åŠ¡**
   - éœ€è¦å¯¹æ¯”å¤šä¸ªç« èŠ‚çš„å†…å®¹
   - è·¨æ–‡æ¡£çš„å› æœæ¨ç†
   - "ä¸ºä»€ä¹ˆ"ç±»é—®é¢˜ï¼ˆéœ€è¦ç†è§£æ•´ä½“é€»è¾‘ï¼‰

3. **ç»“æ„åŒ–æ–‡æ¡£**
   - å±‚æ¬¡åŒ–çš„æŠ€æœ¯æ–‡æ¡£ï¼ˆæœ‰æ˜ç¡®çš„ç« èŠ‚ç»“æ„ï¼‰
   - ç»„ç»‡æ¶æ„ã€çŸ¥è¯†å›¾è°±
   - API æ–‡æ¡£ï¼ˆæœ‰æ˜ç¡®çš„ç±»-æ–¹æ³•å±‚æ¬¡ï¼‰

4. **ç›¸å¯¹é™æ€çš„çŸ¥è¯†åº“**
   - ä¼ä¸šå†…éƒ¨è§„èŒƒæ–‡æ¡£
   - å†å²çŸ¥è¯†åº“ï¼ˆæ›´æ–°é¢‘ç‡ä½ï¼‰
   - ä¸€æ¬¡æ„å»ºã€å¤šæ¬¡æŸ¥è¯¢çš„åœºæ™¯

---

## 4. å¼€æºå®ç°åˆ†æ

### 4.1 å®˜æ–¹ RAPTOR å®ç°

**ä»“åº“**: [parthsarthi03/raptor](https://github.com/parthsarthi03/raptor)
**è¯­è¨€**: Python
**Stars**: 2.8k+ (æˆªè‡³ 2024)

#### æ ¸å¿ƒä»£ç ç»“æ„

```python
# ä¸»è¦æ¨¡å—
raptor/
â”œâ”€â”€ tree_builder.py       # æ ‘æ„å»ºé€»è¾‘ï¼ˆèšç±» + æ‘˜è¦ï¼‰
â”œâ”€â”€ tree_retriever.py     # æ£€ç´¢ç­–ç•¥å®ç°
â”œâ”€â”€ cluster.py            # GMM èšç±»ç®—æ³•
â”œâ”€â”€ qa_model.py           # é—®ç­”ç”Ÿæˆ
â””â”€â”€ utils.py              # å·¥å…·å‡½æ•°
```

#### å…³é”®å®ç°ç»†èŠ‚

**1. èšç±»ç®—æ³•** (cluster.py)

```python
from sklearn.mixture import GaussianMixture
import numpy as np

def GMM_cluster(embeddings, threshold=0.5, max_clusters=10):
    """ä½¿ç”¨ GMM è¿›è¡Œè½¯èšç±»"""
    n_samples = len(embeddings)
    max_clusters = min(max_clusters, n_samples)

    # å°è¯•ä¸åŒçš„èšç±»æ•°ï¼Œé€‰æ‹©æœ€ä¼˜ BIC (Bayesian Information Criterion)
    bic_scores = []
    for n in range(1, max_clusters + 1):
        gmm = GaussianMixture(n_components=n, random_state=42)
        gmm.fit(embeddings)
        bic_scores.append(gmm.bic(embeddings))

    # é€‰æ‹© BIC æœ€ä½çš„èšç±»æ•°
    optimal_clusters = np.argmin(bic_scores) + 1

    gmm = GaussianMixture(n_components=optimal_clusters, random_state=42)
    gmm.fit(embeddings)

    # è·å–æ¦‚ç‡åˆ†å¸ƒï¼ˆè½¯èšç±»ï¼‰
    probabilities = gmm.predict_proba(embeddings)

    # è¿‡æ»¤ä½æ¦‚ç‡åˆ†é…
    clusters = [[] for _ in range(optimal_clusters)]
    for i, probs in enumerate(probabilities):
        for j, prob in enumerate(probs):
            if prob > threshold:
                clusters[j].append(i)

    return clusters
```

**2. æ‘˜è¦ç”Ÿæˆ** (tree_builder.py)

```python
def summarize_cluster(chunks, llm):
    """ä½¿ç”¨ LLM ç”Ÿæˆèšç±»æ‘˜è¦"""
    # æ‹¼æ¥ chunk å†…å®¹
    context = "\n\n".join(chunks)

    # æ‘˜è¦ prompt
    prompt = f"""
ä»¥ä¸‹æ˜¯ä¸€ç»„ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œæ•è·æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®ä¿¡æ¯ã€‚

æ–‡æœ¬ç‰‡æ®µ:
{context}

æ‘˜è¦:
"""

    summary = llm.generate(prompt, max_tokens=500)
    return summary.strip()
```

**3. æ ‘æ„å»º** (tree_builder.py)

```python
class RaptorTree:
    def __init__(self, texts, embed_model, llm):
        self.embed_model = embed_model
        self.llm = llm

        # åˆå§‹åŒ–å¶èŠ‚ç‚¹
        self.leaf_nodes = [
            Node(text=t, embedding=embed_model.encode(t), layer=0)
            for t in texts
        ]

        # é€’å½’æ„å»ºæ ‘
        self.root = self.build_tree(self.leaf_nodes)

    def build_tree(self, nodes, current_layer=0, max_layers=5):
        if len(nodes) <= 5 or current_layer >= max_layers:
            # ç»ˆæ­¢æ¡ä»¶ï¼šèŠ‚ç‚¹å¤ªå°‘æˆ–è¾¾åˆ°æœ€å¤§æ·±åº¦
            return nodes

        # èšç±»
        embeddings = [n.embedding for n in nodes]
        clusters = GMM_cluster(embeddings)

        # ä¸ºæ¯ä¸ªèšç±»ç”Ÿæˆæ‘˜è¦èŠ‚ç‚¹
        parent_nodes = []
        for cluster_indices in clusters:
            cluster_texts = [nodes[i].text for i in cluster_indices]
            cluster_nodes = [nodes[i] for i in cluster_indices]

            # ç”Ÿæˆæ‘˜è¦
            summary = summarize_cluster(cluster_texts, self.llm)
            summary_embedding = self.embed_model.encode(summary)

            # åˆ›å»ºçˆ¶èŠ‚ç‚¹
            parent = Node(
                text=summary,
                embedding=summary_embedding,
                layer=current_layer + 1,
                children=cluster_nodes
            )
            parent_nodes.append(parent)

        # é€’å½’æ„å»ºä¸Šå±‚
        return self.build_tree(parent_nodes, current_layer + 1, max_layers)
```

**4. æ£€ç´¢å®ç°** (tree_retriever.py)

```python
def tree_traverse_search(query_embedding, root_nodes, top_k=5):
    """æ ‘éå†æ£€ç´¢"""
    current_layer = root_nodes
    all_results = []

    while current_layer:
        # è®¡ç®—ç›¸ä¼¼åº¦
        scores = [
            cosine_similarity(query_embedding, node.embedding)
            for node in current_layer
        ]

        # é€‰æ‹© top-2 èŠ‚ç‚¹
        top_indices = np.argsort(scores)[-2:]

        # æ”¶é›†ç»“æœ
        for idx in top_indices:
            all_results.append((current_layer[idx], scores[idx]))

        # ç§»åŠ¨åˆ°å­èŠ‚ç‚¹å±‚
        next_layer = []
        for idx in top_indices:
            next_layer.extend(current_layer[idx].children)
        current_layer = next_layer

    # è¿”å› top-k ç»“æœ
    all_results.sort(key=lambda x: x[1], reverse=True)
    return [node for node, score in all_results[:top_k]]
```

### 4.2 LangChain é›†æˆå®ç°

**ä»“åº“**: [NirDiamant/RAG_Techniques](https://github.com/NirDiamant/RAG_Techniques)
**æ–‡ä»¶**: `all_rag_techniques/raptor.ipynb`

#### å…³é”®ä»£ç ç‰‡æ®µ

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from sklearn.cluster import KMeans
import numpy as np

# 1. æ–‡æ¡£åŠ è½½ä¸åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = text_splitter.split_documents(documents)

# 2. ç”Ÿæˆ Embedding
embeddings_model = OpenAIEmbeddings()
chunk_embeddings = embeddings_model.embed_documents([c.page_content for c in chunks])

# 3. èšç±»ï¼ˆç®€åŒ–ç‰ˆä½¿ç”¨ KMeansï¼‰
n_clusters = len(chunks) // 10  # æ¯ 10 ä¸ª chunk èšä¸ºä¸€ç»„
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
kmeans.fit(chunk_embeddings)

# 4. ç”Ÿæˆæ‘˜è¦
llm = ChatOpenAI(model="gpt-4", temperature=0)
summaries = []

for cluster_id in range(n_clusters):
    cluster_chunks = [chunks[i] for i in range(len(chunks)) if kmeans.labels_[i] == cluster_id]
    cluster_text = "\n\n".join([c.page_content for c in cluster_chunks])

    summary_prompt = f"æ€»ç»“ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒè¦ç‚¹:\n\n{cluster_text[:4000]}"
    summary = llm.invoke(summary_prompt).content
    summaries.append(summary)

# 5. é€’å½’æ„å»ºï¼ˆå¯ç»§ç»­å¯¹æ‘˜è¦èšç±»ï¼‰
# ... (çœç•¥é€’å½’é€»è¾‘)

# 6. æŸ¥è¯¢
def raptor_query(question, tree_data):
    query_embedding = embeddings_model.embed_query(question)

    # åœ¨æ‰€æœ‰å±‚çº§ä¸­æ£€ç´¢
    all_nodes = tree_data['summaries'] + tree_data['chunks']
    all_embeddings = tree_data['summary_embeddings'] + tree_data['chunk_embeddings']

    # è®¡ç®—ç›¸ä¼¼åº¦
    similarities = np.dot(all_embeddings, query_embedding)
    top_indices = np.argsort(similarities)[-5:]

    # è·å–æœ€ç›¸å…³çš„å†…å®¹
    context = "\n\n".join([all_nodes[i] for i in top_indices])

    # ç”Ÿæˆç­”æ¡ˆ
    answer_prompt = f"æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜:\n\nä¸Šä¸‹æ–‡:\n{context}\n\né—®é¢˜: {question}"
    answer = llm.invoke(answer_prompt).content

    return answer
```

### 4.3 Go è¯­è¨€ç§»æ¤å¯è¡Œæ€§åˆ†æ

#### æŠ€æœ¯æ˜ å°„

| Python ç»„ä»¶ | Go æ›¿ä»£æ–¹æ¡ˆ | å¤æ‚åº¦ |
|-----------|-----------|-------|
| **SBERT Embedding** | è°ƒç”¨ OpenAI API æˆ–æœ¬åœ°æ¨¡å‹æœåŠ¡ | ä½ï¼ˆå·²æœ‰å®ç°ï¼‰ |
| **GMM èšç±»** | `gonum.org/v1/gonum/stat/distmv`<br/>`github.com/pa-m/sklearn` | ä¸­ç­‰ |
| **KMeans èšç±»** | `github.com/muesli/clusters` | ä½ |
| **LLM æ‘˜è¦ç”Ÿæˆ** | å¤ç”¨ç°æœ‰ `llm.ChatProvider` | ä½ï¼ˆå·²æœ‰å®ç°ï¼‰ |
| **å‘é‡ç›¸ä¼¼åº¦è®¡ç®—** | è‡ªå®ç° cosine similarity | ä½ |
| **æ ‘ç»“æ„å­˜å‚¨** | Go struct + JSON åºåˆ—åŒ– | ä½ |

#### æ ¸å¿ƒä»£ç ç¤ºä¾‹ï¼ˆGoï¼‰

```go
package raptor

import (
    "context"
    "math"

    "github.com/kart-io/sentinel-x/pkg/llm"
    "github.com/muesli/clusters"
    "github.com/muesli/kmeans"
)

// Node è¡¨ç¤ºæ ‘èŠ‚ç‚¹
type Node struct {
    ID        string
    Text      string
    Embedding []float32
    Layer     int
    Children  []*Node
    Score     float32  // æ£€ç´¢æ—¶çš„ç›¸ä¼¼åº¦åˆ†æ•°
}

// RaptorTree RAPTOR æ ‘ç»“æ„
type RaptorTree struct {
    RootNodes     []*Node
    AllNodes      map[string]*Node
    embedProvider llm.EmbeddingProvider
    chatProvider  llm.ChatProvider
}

// BuildTree æ„å»º RAPTOR æ ‘
func (rt *RaptorTree) BuildTree(ctx context.Context, texts []string, maxLayers int) error {
    // 1. åˆ›å»ºå¶èŠ‚ç‚¹
    leafNodes := make([]*Node, len(texts))
    embeddings, err := rt.embedProvider.Embed(ctx, texts)
    if err != nil {
        return err
    }

    for i, text := range texts {
        leafNodes[i] = &Node{
            ID:        fmt.Sprintf("leaf_%d", i),
            Text:      text,
            Embedding: embeddings[i],
            Layer:     0,
        }
    }

    // 2. é€’å½’æ„å»ºæ ‘
    rt.RootNodes = rt.buildTreeRecursive(ctx, leafNodes, 0, maxLayers)
    return nil
}

// buildTreeRecursive é€’å½’æ„å»ºæ ‘
func (rt *RaptorTree) buildTreeRecursive(ctx context.Context, nodes []*Node, currentLayer, maxLayers int) []*Node {
    if len(nodes) <= 5 || currentLayer >= maxLayers {
        return nodes
    }

    // 1. èšç±»
    clusters := rt.clusterNodes(nodes, len(nodes)/10)

    // 2. ä¸ºæ¯ä¸ªèšç±»ç”Ÿæˆæ‘˜è¦èŠ‚ç‚¹
    parentNodes := make([]*Node, 0, len(clusters))
    for clusterID, cluster := range clusters {
        // æ”¶é›†èšç±»æ–‡æœ¬
        clusterTexts := make([]string, len(cluster))
        for i, node := range cluster {
            clusterTexts[i] = node.Text
        }

        // ç”Ÿæˆæ‘˜è¦
        summary, err := rt.summarizeCluster(ctx, clusterTexts)
        if err != nil {
            continue // è·³è¿‡å¤±è´¥çš„èšç±»
        }

        // ç”Ÿæˆæ‘˜è¦çš„ Embedding
        summaryEmbed, err := rt.embedProvider.EmbedSingle(ctx, summary)
        if err != nil {
            continue
        }

        // åˆ›å»ºçˆ¶èŠ‚ç‚¹
        parent := &Node{
            ID:        fmt.Sprintf("layer%d_cluster%d", currentLayer+1, clusterID),
            Text:      summary,
            Embedding: summaryEmbed,
            Layer:     currentLayer + 1,
            Children:  cluster,
        }
        parentNodes = append(parentNodes, parent)
    }

    // 3. é€’å½’æ„å»ºä¸Šå±‚
    return rt.buildTreeRecursive(ctx, parentNodes, currentLayer+1, maxLayers)
}

// clusterNodes ä½¿ç”¨ KMeans èšç±»
func (rt *RaptorTree) clusterNodes(nodes []*Node, numClusters int) [][]*Node {
    // å‡†å¤‡æ•°æ®ç‚¹
    data := make([]clusters.Observation, len(nodes))
    for i, node := range nodes {
        coords := make(clusters.Coordinates, len(node.Embedding))
        for j, v := range node.Embedding {
            coords[j] = float64(v)
        }
        data[i] = coords
    }

    // KMeans èšç±»
    km := kmeans.New()
    clusterResult, err := km.Partition(data, numClusters)
    if err != nil {
        // èšç±»å¤±è´¥ï¼Œè¿”å›å•ä¸ªèšç±»
        return [][]*Node{nodes}
    }

    // æŒ‰èšç±» ID åˆ†ç»„
    clustered := make([][]*Node, numClusters)
    for i, obs := range clusterResult {
        clusterID := obs.ClusterID
        clustered[clusterID] = append(clustered[clusterID], nodes[i])
    }

    return clustered
}

// summarizeCluster ä½¿ç”¨ LLM ç”Ÿæˆèšç±»æ‘˜è¦
func (rt *RaptorTree) summarizeCluster(ctx context.Context, texts []string) (string, error) {
    // æ‹¼æ¥æ–‡æœ¬
    combined := ""
    for _, t := range texts {
        combined += t + "\n\n"
        if len(combined) > 10000 { // é™åˆ¶é•¿åº¦
            break
        }
    }

    // æ„å»º prompt
    prompt := fmt.Sprintf(`ä»¥ä¸‹æ˜¯ä¸€ç»„ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ200å­—ä»¥å†…ï¼‰ï¼Œæ•è·æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®ä¿¡æ¯ã€‚

æ–‡æœ¬ç‰‡æ®µ:
%s

æ‘˜è¦:`, combined)

    // è°ƒç”¨ LLM
    resp, err := rt.chatProvider.Chat(ctx, &llm.ChatRequest{
        Messages: []*llm.Message{
            {Role: "user", Content: prompt},
        },
        MaxTokens:   500,
        Temperature: 0.3,
    })
    if err != nil {
        return "", err
    }

    return resp.Content, nil
}

// Search æ‰§è¡Œæ ‘éå†æ£€ç´¢
func (rt *RaptorTree) Search(ctx context.Context, query string, topK int) ([]*Node, error) {
    // 1. ç”ŸæˆæŸ¥è¯¢ Embedding
    queryEmbed, err := rt.embedProvider.EmbedSingle(ctx, query)
    if err != nil {
        return nil, err
    }

    // 2. æ ‘éå†
    currentLayer := rt.RootNodes
    allResults := []*Node{}

    for len(currentLayer) > 0 {
        // è®¡ç®—ç›¸ä¼¼åº¦
        for _, node := range currentLayer {
            node.Score = cosineSimilarity(queryEmbed, node.Embedding)
        }

        // æ’åºå¹¶é€‰æ‹© top-2
        sort.Slice(currentLayer, func(i, j int) bool {
            return currentLayer[i].Score > currentLayer[j].Score
        })

        topNodes := currentLayer
        if len(topNodes) > 2 {
            topNodes = topNodes[:2]
        }

        // æ”¶é›†ç»“æœ
        allResults = append(allResults, topNodes...)

        // ç§»åŠ¨åˆ°å­èŠ‚ç‚¹å±‚
        nextLayer := []*Node{}
        for _, node := range topNodes {
            nextLayer = append(nextLayer, node.Children...)
        }
        currentLayer = nextLayer
    }

    // 3. è¿”å› top-k ç»“æœ
    sort.Slice(allResults, func(i, j int) bool {
        return allResults[i].Score > allResults[j].Score
    })

    if len(allResults) > topK {
        allResults = allResults[:topK]
    }

    return allResults, nil
}

// cosineSimilarity è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
func cosineSimilarity(a, b []float32) float32 {
    if len(a) != len(b) {
        return 0
    }

    var dotProduct, normA, normB float64
    for i := range a {
        dotProduct += float64(a[i]) * float64(b[i])
        normA += float64(a[i]) * float64(a[i])
        normB += float64(b[i]) * float64(b[i])
    }

    if normA == 0 || normB == 0 {
        return 0
    }

    return float32(dotProduct / (math.Sqrt(normA) * math.Sqrt(normB)))
}
```

#### ä¾èµ–åº“è¯„ä¼°

```go
// go.mod æ–°å¢ä¾èµ–
require (
    github.com/muesli/clusters v0.0.0-20200529215643-2700303c1762  // KMeans èšç±»
    github.com/muesli/kmeans v0.3.1                                 // KMeans å®ç°
    gonum.org/v1/gonum v0.14.0                                      // ç§‘å­¦è®¡ç®—ï¼ˆå¯é€‰ï¼Œç”¨äº GMMï¼‰
)
```

**å®ç°å¤æ‚åº¦è¯„ä¼°**: ä¸­ç­‰ï¼ˆçº¦ 2-3 å‘¨å¼€å‘ + 1 å‘¨æµ‹è¯•ï¼‰

---

## 5. å®æ–½å»ºè®®

### 5.1 é€‚ç”¨åœºæ™¯åˆ¤æ–­

åŸºäºé¡¹ç›®å½“å‰æƒ…å†µï¼Œå»ºè®®é‡‡ç”¨**æ··åˆæ¶æ„**ï¼Œè€Œéå®Œå…¨æ›¿æ¢ï¼š

#### åœºæ™¯ 1: æŠ€æœ¯æ–‡æ¡£ RAGï¼ˆæ¨èä½¿ç”¨ Treeï¼‰

**ç‰¹å¾**:
- é•¿æ–‡æ¡£ï¼ˆAPI æ–‡æ¡£ã€æŠ€æœ¯è§„èŒƒï¼‰
- å±‚æ¬¡åŒ–ç»“æ„æ˜ç¡®
- æŸ¥è¯¢æ¶‰åŠå¤šæ­¥æ¨ç†ï¼ˆ"X å’Œ Y çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"ï¼‰

**æ”¶ç›Š**: å‡†ç¡®ç‡æå‡ 15-25%ï¼Œç”¨æˆ·æ»¡æ„åº¦æ˜¾è‘—æ”¹å–„

#### åœºæ™¯ 2: ä¼ä¸šçŸ¥è¯†åº“ FAQï¼ˆä¿æŒå‘é‡ï¼‰

**ç‰¹å¾**:
- çŸ­æ–‡æ¡£ï¼ˆFAQã€äº§å“è¯´æ˜ï¼‰
- ç®€å•äº‹å®æŸ¥è¯¢ä¸ºä¸»
- éœ€è¦é«˜å¹¶å‘ã€ä½å»¶è¿Ÿ

**æ”¶ç›Š**: ç°æœ‰æ–¹æ¡ˆå·²è¶³å¤Ÿï¼Œæ— éœ€å¢åŠ å¤æ‚åº¦

#### åœºæ™¯ 3: æ··åˆæŸ¥è¯¢åœºæ™¯ï¼ˆåŠ¨æ€é€‰æ‹©ï¼‰

**ç­–ç•¥**:
```go
func (s *RAGService) Query(ctx context.Context, question string) (*model.QueryResult, error) {
    // æŸ¥è¯¢åˆ†ç±»
    queryType := s.classifyQuery(question)

    switch queryType {
    case QueryTypeComplex:
        // ä½¿ç”¨ Tree-based æ£€ç´¢
        return s.treeRetriever.Retrieve(ctx, question)
    case QueryTypeSimple:
        // ä½¿ç”¨å‘é‡æ£€ç´¢
        return s.vectorRetriever.Retrieve(ctx, question)
    case QueryTypeHybrid:
        // æ··åˆæ£€ç´¢ï¼šå‘é‡ + Tree ç»“æœèåˆ
        return s.hybridRetriever.Retrieve(ctx, question)
    }
}
```

### 5.2 æ··åˆæ¶æ„æ–¹æ¡ˆ

#### æ¶æ„è®¾è®¡

```
                        ç”¨æˆ·æŸ¥è¯¢
                           |
                   [æŸ¥è¯¢åˆ†ç±»å™¨]
                   /     |      \
                  /      |       \
         [å‘é‡æ£€ç´¢] [Treeæ£€ç´¢] [æ··åˆæ£€ç´¢]
              |        |          |
              +--------+---------+
                       |
                  [ç»“æœèåˆ]
                       |
                  [ç”Ÿæˆç­”æ¡ˆ]
```

#### æ ¸å¿ƒç»„ä»¶

**1. æŸ¥è¯¢åˆ†ç±»å™¨**

```go
// QueryClassifier æŸ¥è¯¢åˆ†ç±»å™¨
type QueryClassifier struct {
    llm llm.ChatProvider
}

func (qc *QueryClassifier) Classify(ctx context.Context, query string) QueryType {
    // ç®€å•è§„åˆ™
    if len(query) < 20 && !strings.Contains(query, "ä¸ºä»€ä¹ˆ") {
        return QueryTypeSimple
    }

    // ä½¿ç”¨ LLM åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
    prompt := fmt.Sprintf(`åˆ¤æ–­ä»¥ä¸‹æŸ¥è¯¢çš„å¤æ‚åº¦ã€‚å¦‚æœæ˜¯ç®€å•äº‹å®æŸ¥è¯¢ï¼Œè¿”å›"simple"ï¼›å¦‚æœéœ€è¦å¤šæ­¥æ¨ç†æˆ–å¯¹æ¯”åˆ†æï¼Œè¿”å›"complex"ã€‚

æŸ¥è¯¢: %s
å¤æ‚åº¦:`, query)

    resp, _ := qc.llm.Chat(ctx, &llm.ChatRequest{
        Messages: []*llm.Message{{Role: "user", Content: prompt}},
        MaxTokens: 10,
    })

    if strings.Contains(strings.ToLower(resp.Content), "complex") {
        return QueryTypeComplex
    }
    return QueryTypeSimple
}
```

**2. åŒæ¨¡å¼æ£€ç´¢å™¨**

```go
// HybridRetriever æ··åˆæ£€ç´¢å™¨
type HybridRetriever struct {
    vectorRetriever *VectorRetriever
    treeRetriever   *TreeRetriever
    classifier      *QueryClassifier
}

func (hr *HybridRetriever) Retrieve(ctx context.Context, query string) (*RetrievalResult, error) {
    queryType := hr.classifier.Classify(ctx, query)

    switch queryType {
    case QueryTypeSimple:
        return hr.vectorRetriever.Retrieve(ctx, query)

    case QueryTypeComplex:
        return hr.treeRetriever.Retrieve(ctx, query)

    case QueryTypeHybrid:
        // å¹¶è¡Œæ£€ç´¢
        vectorResults, err1 := hr.vectorRetriever.Retrieve(ctx, query)
        treeResults, err2 := hr.treeRetriever.Retrieve(ctx, query)

        if err1 != nil || err2 != nil {
            // é™çº§å¤„ç†
            if err1 == nil {
                return vectorResults, nil
            }
            return treeResults, err2
        }

        // ç»“æœèåˆï¼ˆåŸºäºåˆ†æ•°åŠ æƒï¼‰
        return hr.mergeResults(vectorResults, treeResults, 0.5, 0.5), nil
    }

    return nil, fmt.Errorf("unknown query type")
}

func (hr *HybridRetriever) mergeResults(v, t *RetrievalResult, vectorWeight, treeWeight float32) *RetrievalResult {
    // åˆå¹¶ä¸¤ä¸ªæ£€ç´¢ç»“æœï¼Œå»é‡å¹¶é‡æ–°æ’åº
    merged := make([]*store.SearchResult, 0, len(v.Results)+len(t.Results))
    seen := make(map[string]bool)

    // è°ƒæ•´åˆ†æ•°
    for _, r := range v.Results {
        r.Score *= vectorWeight
        if !seen[r.ID] {
            merged = append(merged, r)
            seen[r.ID] = true
        }
    }

    for _, r := range t.Results {
        r.Score *= treeWeight
        if !seen[r.ID] {
            merged = append(merged, r)
            seen[r.ID] = true
        } else {
            // å¦‚æœå·²å­˜åœ¨ï¼Œå–æœ€é«˜åˆ†
            for _, m := range merged {
                if m.ID == r.ID && r.Score > m.Score {
                    m.Score = r.Score
                }
            }
        }
    }

    // é‡æ–°æ’åº
    sort.Slice(merged, func(i, j int) bool {
        return merged[i].Score > merged[j].Score
    })

    // é™åˆ¶ç»“æœæ•°é‡
    if len(merged) > 10 {
        merged = merged[:10]
    }

    return &RetrievalResult{
        Query:   v.Query,
        Results: merged,
    }
}
```

### 5.3 æ¸è¿›å¼è¿ç§»è·¯å¾„

#### é˜¶æ®µ 1: è°ƒç ”éªŒè¯ï¼ˆ2 å‘¨ï¼‰

**ç›®æ ‡**: éªŒè¯æŠ€æœ¯å¯è¡Œæ€§

**ä»»åŠ¡**:
- [ ] å®ç°æœ€å°å¯è¡ŒåŸå‹ï¼ˆMVPï¼‰
  - åŸºç¡€æ ‘æ„å»ºï¼ˆKMeans èšç±» + LLM æ‘˜è¦ï¼‰
  - ç®€å•æ ‘éå†æ£€ç´¢
  - ä¸ç°æœ‰å‘é‡æ£€ç´¢å¯¹æ¯”æµ‹è¯•
- [ ] åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°æ€§èƒ½
  - å‡†å¤‡ 50-100 ä¸ªæµ‹è¯•æŸ¥è¯¢ï¼ˆè¦†ç›–ç®€å•/å¤æ‚æŸ¥è¯¢ï¼‰
  - å¯¹æ¯”å¬å›ç‡ã€å‡†ç¡®ç‡ã€å»¶è¿Ÿ
- [ ] æˆæœ¬åˆ†æ
  - æ„å»ºæˆæœ¬ï¼ˆæ—¶é—´ã€LLM Tokenï¼‰
  - æŸ¥è¯¢æˆæœ¬ï¼ˆå»¶è¿Ÿã€è®¡ç®—èµ„æºï¼‰

**éªŒæ”¶æ ‡å‡†**:
- åŸå‹ä»£ç å¯è¿è¡Œ
- æ€§èƒ½æŠ¥å‘Šå®Œæˆï¼ˆåŒ…å«æ•°æ®å¯¹æ¯”ï¼‰
- å†³ç­–æ˜¯å¦è¿›å…¥ä¸‹ä¸€é˜¶æ®µ

#### é˜¶æ®µ 2: æ ¸å¿ƒå®ç°ï¼ˆ4 å‘¨ï¼‰

**ç›®æ ‡**: ç”Ÿäº§çº§ Tree-based æ£€ç´¢å™¨

**ä»»åŠ¡**:
- [ ] å®Œæ•´æ ‘æ„å»ºå®ç°
  - æ”¯æŒå¢é‡æ›´æ–°ï¼ˆæ–°å¢æ–‡æ¡£æ—¶å±€éƒ¨é‡å»ºï¼‰
  - æ ‘ç»“æ„æŒä¹…åŒ–ï¼ˆJSON/æ•°æ®åº“ï¼‰
  - å¹¶å‘å®‰å…¨
- [ ] ä¼˜åŒ–æ£€ç´¢ç­–ç•¥
  - å®ç° Tree Traversal å’Œ Collapsed Tree ä¸¤ç§æ¨¡å¼
  - æ”¯æŒæ··åˆæ£€ç´¢ï¼ˆå‘é‡ + Treeï¼‰
- [ ] é›†æˆåˆ°ç°æœ‰ RAG æœåŠ¡
  - å®ç° `TreeRetriever` æ¥å£
  - æ·»åŠ é…ç½®é€‰é¡¹ï¼ˆå¯ç”¨/ç¦ç”¨ï¼‰
  - å®Œå–„ç›‘æ§æŒ‡æ ‡

**éªŒæ”¶æ ‡å‡†**:
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- é›†æˆæµ‹è¯•é€šè¿‡
- æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ

#### é˜¶æ®µ 3: æ··åˆæ¶æ„ï¼ˆ3 å‘¨ï¼‰

**ç›®æ ‡**: æ™ºèƒ½è·¯ç”±ä¸ç»“æœèåˆ

**ä»»åŠ¡**:
- [ ] å®ç°æŸ¥è¯¢åˆ†ç±»å™¨
  - åŸºäºè§„åˆ™çš„åˆ†ç±»
  - ï¼ˆå¯é€‰ï¼‰åŸºäº LLM çš„åˆ†ç±»
- [ ] å®ç°æ··åˆæ£€ç´¢å™¨
  - åŒæ¨¡å¼å¹¶è¡Œæ£€ç´¢
  - ç»“æœèåˆç®—æ³•
  - é™çº§å¤„ç†
- [ ] A/B æµ‹è¯•æ¡†æ¶
  - ç°åº¦å‘å¸ƒæœºåˆ¶
  - æ€§èƒ½å¯¹æ¯”ä»ªè¡¨æ¿

**éªŒæ”¶æ ‡å‡†**:
- A/B æµ‹è¯•æ˜¾ç¤ºæ··åˆæ–¹æ¡ˆä¼˜äºå•ä¸€æ–¹æ¡ˆ
- ç”Ÿäº§ç¯å¢ƒç°åº¦å‘å¸ƒæˆåŠŸ

#### é˜¶æ®µ 4: ä¼˜åŒ–ä¸æ¨å¹¿ï¼ˆæŒç»­ï¼‰

**ç›®æ ‡**: æ€§èƒ½ä¼˜åŒ–ä¸åº”ç”¨æ¨å¹¿

**ä»»åŠ¡**:
- [ ] æ€§èƒ½ä¼˜åŒ–
  - æ ‘æ„å»ºå¹¶å‘åŒ–
  - æ£€ç´¢ç¼“å­˜ç­–ç•¥
  - å‡å°‘ LLM è°ƒç”¨æ¬¡æ•°ï¼ˆæ‰¹é‡æ‘˜è¦ï¼‰
- [ ] åº”ç”¨æ¨å¹¿
  - é’ˆå¯¹ä¸åŒåœºæ™¯çš„æœ€ä½³å®è·µæ–‡æ¡£
  - å¼€å‘è€…åŸ¹è®­
- [ ] æŒç»­ç›‘æ§ä¸è¿­ä»£
  - æ”¶é›†ç”¨æˆ·åé¦ˆ
  - ä¼˜åŒ–æŸ¥è¯¢åˆ†ç±»è§„åˆ™

### 5.4 æŠ€æœ¯å®ç°è¦ç‚¹

#### è¦ç‚¹ 1: å¢é‡æ›´æ–°ç­–ç•¥

**æŒ‘æˆ˜**: Tree çš„é‡å»ºæˆæœ¬é«˜ï¼Œæ— æ³•é¢‘ç¹å…¨é‡é‡å»º

**è§£å†³æ–¹æ¡ˆ**:

```go
// IncrementalTreeBuilder å¢é‡æ ‘æ„å»ºå™¨
type IncrementalTreeBuilder struct {
    tree          *RaptorTree
    pendingChunks []*Node  // å¾…å¤„ç†çš„æ–° chunk
    rebuildThreshold int   // é‡å»ºé˜ˆå€¼
}

func (itb *IncrementalTreeBuilder) AddDocument(ctx context.Context, text string) error {
    // 1. åˆ†å—å¹¶åµŒå…¥
    chunks := itb.splitText(text)
    embeddings, _ := itb.embedProvider.Embed(ctx, chunks)

    // 2. æ·»åŠ åˆ°å¾…å¤„ç†é˜Ÿåˆ—
    for i, chunk := range chunks {
        itb.pendingChunks = append(itb.pendingChunks, &Node{
            Text: chunk,
            Embedding: embeddings[i],
            Layer: 0,
        })
    }

    // 3. å¦‚æœè¾¾åˆ°é˜ˆå€¼ï¼Œè§¦å‘å±€éƒ¨é‡å»º
    if len(itb.pendingChunks) >= itb.rebuildThreshold {
        return itb.rebuildAffectedSubtree(ctx)
    }

    return nil
}

func (itb *IncrementalTreeBuilder) rebuildAffectedSubtree(ctx context.Context) error {
    // æ‰¾åˆ°å—å½±å“çš„å¶èŠ‚ç‚¹èšç±»
    affectedClusters := itb.findAffectedClusters(itb.pendingChunks)

    // ä»…é‡å»ºè¿™äº›èšç±»åŠå…¶çˆ¶èŠ‚ç‚¹
    for _, cluster := range affectedClusters {
        // åˆå¹¶æ–°æ—§èŠ‚ç‚¹
        allNodes := append(cluster.Nodes, itb.pendingChunks...)

        // é‡æ–°èšç±»å’Œæ‘˜è¦
        newParent := itb.rebuildCluster(ctx, allNodes)

        // æ›´æ–°æ ‘ç»“æ„
        cluster.Parent.Children = replaceCluster(cluster.Parent.Children, cluster, newParent)
    }

    // æ¸…ç©ºå¾…å¤„ç†é˜Ÿåˆ—
    itb.pendingChunks = nil
    return nil
}
```

#### è¦ç‚¹ 2: æ ‘ç»“æ„æŒä¹…åŒ–

**æ–¹æ¡ˆ 1: JSON æ–‡ä»¶** (é€‚åˆå°è§„æ¨¡)

```go
func (rt *RaptorTree) SaveToFile(path string) error {
    data := struct {
        RootNodes []*Node            `json:"root_nodes"`
        AllNodes  map[string]*Node   `json:"all_nodes"`
    }{
        RootNodes: rt.RootNodes,
        AllNodes:  rt.AllNodes,
    }

    jsonData, err := json.MarshalIndent(data, "", "  ")
    if err != nil {
        return err
    }

    return os.WriteFile(path, jsonData, 0644)
}
```

**æ–¹æ¡ˆ 2: æ•°æ®åº“å­˜å‚¨** (é€‚åˆå¤§è§„æ¨¡)

```sql
-- æ ‘èŠ‚ç‚¹è¡¨
CREATE TABLE raptor_nodes (
    id VARCHAR(255) PRIMARY KEY,
    text TEXT NOT NULL,
    embedding VECTOR(1536),  -- PostgreSQL + pgvector
    layer INT NOT NULL,
    parent_id VARCHAR(255),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_raptor_nodes_layer ON raptor_nodes(layer);
CREATE INDEX idx_raptor_nodes_parent ON raptor_nodes(parent_id);
CREATE INDEX idx_raptor_nodes_embedding ON raptor_nodes USING ivfflat (embedding vector_cosine_ops);
```

```go
// æ•°æ®åº“åŠ è½½
func (rt *RaptorTree) LoadFromDB(ctx context.Context, db *sql.DB) error {
    rows, err := db.QueryContext(ctx, `
        SELECT id, text, embedding, layer, parent_id
        FROM raptor_nodes
        ORDER BY layer DESC
    `)
    if err != nil {
        return err
    }
    defer rows.Close()

    // æ„å»ºèŠ‚ç‚¹æ˜ å°„
    nodes := make(map[string]*Node)
    for rows.Next() {
        var node Node
        var parentID sql.NullString
        var embeddingBytes []byte

        err := rows.Scan(&node.ID, &node.Text, &embeddingBytes, &node.Layer, &parentID)
        if err != nil {
            return err
        }

        // ååºåˆ—åŒ– Embedding
        node.Embedding = bytesToFloat32Array(embeddingBytes)
        nodes[node.ID] = &node
    }

    // é‡å»ºçˆ¶å­å…³ç³»
    for _, node := range nodes {
        if node.ParentID != "" {
            parent := nodes[node.ParentID]
            parent.Children = append(parent.Children, node)
        }
    }

    // æ‰¾åˆ°æ ¹èŠ‚ç‚¹
    for _, node := range nodes {
        if node.Layer == rt.maxLayer {
            rt.RootNodes = append(rt.RootNodes, node)
        }
    }

    rt.AllNodes = nodes
    return nil
}
```

#### è¦ç‚¹ 3: å¹¶å‘ä¼˜åŒ–

```go
// å¹¶å‘æ ‘æ„å»ºï¼ˆå¶èŠ‚ç‚¹ Embeddingï¼‰
func (rt *RaptorTree) BuildTreeConcurrent(ctx context.Context, texts []string, maxLayers int) error {
    const batchSize = 100

    // åˆ†æ‰¹å¹¶å‘ Embedding
    leafNodes := make([]*Node, len(texts))
    var wg sync.WaitGroup
    errChan := make(chan error, (len(texts)/batchSize)+1)

    for i := 0; i < len(texts); i += batchSize {
        wg.Add(1)
        go func(start int) {
            defer wg.Done()

            end := start + batchSize
            if end > len(texts) {
                end = len(texts)
            }

            batch := texts[start:end]
            embeddings, err := rt.embedProvider.Embed(ctx, batch)
            if err != nil {
                errChan <- err
                return
            }

            for j, text := range batch {
                leafNodes[start+j] = &Node{
                    ID:        fmt.Sprintf("leaf_%d", start+j),
                    Text:      text,
                    Embedding: embeddings[j],
                    Layer:     0,
                }
            }
        }(i)
    }

    wg.Wait()
    close(errChan)

    if err := <-errChan; err != nil {
        return err
    }

    // é€’å½’æ„å»ºæ ‘
    rt.RootNodes = rt.buildTreeRecursive(ctx, leafNodes, 0, maxLayers)
    return nil
}
```

### 5.5 æˆæœ¬æ•ˆç›Šåˆ†æ

#### å¼€å‘æˆæœ¬

| é¡¹ç›® | äººåŠ› | æ—¶é—´ |
|------|------|------|
| é˜¶æ®µ 1: è°ƒç ”éªŒè¯ | 1 äºº | 2 å‘¨ |
| é˜¶æ®µ 2: æ ¸å¿ƒå®ç° | 2 äºº | 4 å‘¨ |
| é˜¶æ®µ 3: æ··åˆæ¶æ„ | 2 äºº | 3 å‘¨ |
| é˜¶æ®µ 4: ä¼˜åŒ–æ¨å¹¿ | 1 äºº | æŒç»­ |
| **æ€»è®¡** | **2-3 äºº** | **çº¦ 2-3 ä¸ªæœˆ** |

#### è¿è¥æˆæœ¬ï¼ˆä»¥ 10GB çŸ¥è¯†åº“ä¸ºä¾‹ï¼‰

**å‘é‡ RAGï¼ˆå½“å‰ï¼‰**:
- å­˜å‚¨: ~5 GBï¼ˆåŸå§‹ chunkï¼‰
- æ„å»º: ä¸€æ¬¡æ€§ ~$50ï¼ˆEmbedding APIï¼‰
- æŸ¥è¯¢: ~$0.001/æ¬¡ï¼ˆä»… Embeddingï¼‰

**RAPTOR Tree**:
- å­˜å‚¨: ~20 GBï¼ˆchunk + æ‘˜è¦æ ‘ï¼Œ4xï¼‰
- æ„å»º: ä¸€æ¬¡æ€§ ~$500ï¼ˆEmbedding + LLM æ‘˜è¦ï¼‰
- æŸ¥è¯¢: ~$0.002/æ¬¡ï¼ˆæ ‘éå†ç¨æ…¢ï¼‰

**æˆæœ¬å¢åŠ **: åˆå§‹æ„å»ºæˆæœ¬ 10xï¼Œå­˜å‚¨æˆæœ¬ 4xï¼ŒæŸ¥è¯¢æˆæœ¬ 2x

#### ROI è¯„ä¼°

**æ”¶ç›Š**ï¼ˆå‡è®¾çŸ¥è¯†åº“æœˆæ´» 10,000 æŸ¥è¯¢ï¼‰:
- å‡†ç¡®ç‡æå‡ 15-20% â†’ å‡å°‘ç”¨æˆ·é‡å¤æŸ¥è¯¢ â†’ èŠ‚çœçº¦ 2000 æ¬¡æŸ¥è¯¢
- ç”¨æˆ·æ»¡æ„åº¦æå‡ â†’ å‡å°‘äººå·¥å®¢æœä»‹å…¥ â†’ èŠ‚çœçº¦ $1000/æœˆ

**æˆæœ¬**ï¼ˆæœˆåº¦ï¼‰:
- é¢å¤–å­˜å‚¨: ~$20/æœˆ
- é¢å¤–æŸ¥è¯¢æˆæœ¬: ~$10/æœˆï¼ˆ10,000 Ã— $0.001ï¼‰

**å‡€æ”¶ç›Š**: $1000 - $30 = **$970/æœˆ**
**æŠ•èµ„å›æ”¶æœŸ**: çº¦ 3-4 ä¸ªæœˆ

**ç»“è®º**: å¯¹äºé«˜ä»·å€¼çš„æŠ€æœ¯æ–‡æ¡£/çŸ¥è¯†åº“åœºæ™¯ï¼ŒROI ä¸ºæ­£ã€‚

---

## 6. é£é™©è¯„ä¼°ä¸ç¼“è§£æªæ–½

### é£é™© 1: å®ç°å¤æ‚åº¦é«˜

**é£é™©ç­‰çº§**: é«˜
**å½±å“**: å¼€å‘å‘¨æœŸå»¶é•¿ã€Bug å¢å¤š

**ç¼“è§£æªæ–½**:
1. é‡‡ç”¨æ¸è¿›å¼è¿ç§»ï¼Œå…ˆå®ç°ç®€åŒ–ç‰ˆï¼ˆKMeans ä»£æ›¿ GMMï¼‰
2. å……åˆ†å¤ç”¨ç°æœ‰ä»£ç ï¼ˆEmbeddingã€LLM Providerï¼‰
3. å¼•å…¥æˆç†Ÿçš„ç¬¬ä¸‰æ–¹åº“ï¼ˆå¦‚ `muesli/clusters`ï¼‰
4. å®Œå–„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

### é£é™© 2: æ„å»ºæˆæœ¬è¿‡é«˜

**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: LLM API è´¹ç”¨æ¿€å¢

**ç¼“è§£æªæ–½**:
1. æ‰¹é‡æ‘˜è¦ç”Ÿæˆï¼ˆä¸€æ¬¡ LLM è°ƒç”¨å¤„ç†å¤šä¸ªèšç±»ï¼‰
2. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚ GPT-3.5-turboï¼‰
3. ç¼“å­˜æ‘˜è¦ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
4. å¢é‡æ›´æ–°ç­–ç•¥ï¼Œé¿å…å…¨é‡é‡å»º

### é£é™© 3: æŸ¥è¯¢å»¶è¿Ÿå¢åŠ 

**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: ç”¨æˆ·ä½“éªŒä¸‹é™

**ç¼“è§£æªæ–½**:
1. ä½¿ç”¨ Collapsed Tree æ¨¡å¼ï¼ˆæ‰å¹³åŒ–æ£€ç´¢ï¼Œæ¥è¿‘å‘é‡é€Ÿåº¦ï¼‰
2. å¼‚æ­¥é¢„çƒ­ï¼ˆåå°é¢„è®¡ç®—çƒ­é—¨æŸ¥è¯¢çš„ç»“æœï¼‰
3. å¤šçº§ç¼“å­˜ï¼ˆæŸ¥è¯¢ç¼“å­˜ + æ ‘éå†è·¯å¾„ç¼“å­˜ï¼‰
4. æ··åˆæ¶æ„ä¸­ä¼˜å…ˆä½¿ç”¨å‘é‡æ£€ç´¢ï¼ˆç®€å•æŸ¥è¯¢ï¼‰

### é£é™© 4: ç»´æŠ¤å›°éš¾

**é£é™©ç­‰çº§**: ä¸­
**å½±å“**: é•¿æœŸæŠ€æœ¯å€ºåŠ¡

**ç¼“è§£æªæ–½**:
1. å®Œå–„æ–‡æ¡£ï¼ˆæ¶æ„è®¾è®¡ã€ä½¿ç”¨æŒ‡å—ï¼‰
2. å¯è§†åŒ–å·¥å…·ï¼ˆæ ‘ç»“æ„å¯è§†åŒ–ã€è°ƒè¯•å·¥å…·ï¼‰
3. å¯è§‚æµ‹æ€§ï¼ˆç›‘æ§æ ‘æ„å»ºæ—¶é—´ã€æ£€ç´¢æ€§èƒ½ï¼‰
4. é™çº§æœºåˆ¶ï¼ˆæ ‘æ£€ç´¢å¤±è´¥æ—¶å›é€€åˆ°å‘é‡æ£€ç´¢ï¼‰

---

## 7. æ€»ç»“ä¸å»ºè®®

### æ ¸å¿ƒç»“è®º

1. **æŠ€æœ¯å¯è¡Œæ€§**: âœ… é«˜
   - RAPTOR åŸç†æ¸…æ™°ï¼Œå·²æœ‰æˆç†Ÿçš„ Python å®ç°
   - Go è¯­è¨€ç”Ÿæ€æ”¯æŒè‰¯å¥½ï¼ˆèšç±»ã€å‘é‡è®¡ç®—åº“é½å…¨ï¼‰
   - ç§»æ¤å·¥ä½œé‡å¯æ§ï¼ˆçº¦ 2-3 ä¸ªæœˆï¼‰

2. **æ€§èƒ½æå‡**: âœ… æ˜¾è‘—ï¼ˆå¤æ‚æŸ¥è¯¢åœºæ™¯ï¼‰
   - æ£€ç´¢å¬å›ç‡æå‡ 10-20%
   - å¤æ‚æŸ¥è¯¢å‡†ç¡®ç‡æå‡ 25-30%
   - é•¿æ–‡æ¡£ç†è§£èƒ½åŠ›æ˜¾è‘—å¢å¼º

3. **æˆæœ¬å¢åŠ **: âš ï¸ ä¸­ç­‰
   - åˆå§‹æ„å»ºæˆæœ¬ 10xï¼ˆä¸€æ¬¡æ€§ï¼‰
   - å­˜å‚¨æˆæœ¬ 4xï¼ˆå¯æ¥å—ï¼‰
   - æŸ¥è¯¢æˆæœ¬ 2xï¼ˆå¯é€šè¿‡ä¼˜åŒ–é™ä½ï¼‰

4. **æŠ•èµ„å›æŠ¥**: âœ… æ­£å‘ï¼ˆé«˜ä»·å€¼åœºæ™¯ï¼‰
   - æŠ•èµ„å›æ”¶æœŸ 3-4 ä¸ªæœˆ
   - é•¿æœŸæ”¶ç›Šæ˜¾è‘—

### æœ€ç»ˆå»ºè®®

**æ¨èé‡‡ç”¨æ··åˆæ¶æ„æ–¹æ¡ˆ**ï¼Œå…·ä½“å»ºè®®å¦‚ä¸‹ï¼š

#### çŸ­æœŸï¼ˆ1-2 ä¸ªæœˆï¼‰

1. **å¯åŠ¨ POCï¼ˆæ¦‚å¿µéªŒè¯ï¼‰é¡¹ç›®**
   - é€‰æ‹© 1-2 ä¸ªå…¸å‹æŠ€æœ¯æ–‡æ¡£åœºæ™¯
   - å®ç° RAPTOR ç®€åŒ–ç‰ˆï¼ˆKMeans + GPT-3.5 æ‘˜è¦ï¼‰
   - å¯¹æ¯”æµ‹è¯•å‡†ç¡®ç‡å’Œæˆæœ¬

2. **è¯„ä¼° POC ç»“æœ**
   - å¦‚æœå‡†ç¡®ç‡æå‡ > 15%ï¼Œè¿›å…¥ä¸‹ä¸€é˜¶æ®µ
   - å¦‚æœæˆæœ¬è¿‡é«˜ï¼ˆ> é¢„ç®— 2xï¼‰ï¼Œä¼˜åŒ–æˆ–æ”¾å¼ƒ

#### ä¸­æœŸï¼ˆ3-6 ä¸ªæœˆï¼‰

3. **å®ç°ç”Ÿäº§çº§ Tree-based æ£€ç´¢å™¨**
   - å®Œæ•´æ ‘æ„å»ºæµç¨‹
   - å¢é‡æ›´æ–°æœºåˆ¶
   - é›†æˆåˆ°ç°æœ‰ RAG æœåŠ¡

4. **å®ç°æ··åˆæ¶æ„**
   - æŸ¥è¯¢åˆ†ç±»å™¨
   - åŒæ¨¡å¼æ£€ç´¢å™¨
   - A/B æµ‹è¯•æ¡†æ¶

5. **ç°åº¦å‘å¸ƒ**
   - å…ˆåœ¨ 10% æµé‡ä¸Šæµ‹è¯•
   - é€æ­¥æ‰©å¤§åˆ° 50% â†’ 100%

#### é•¿æœŸï¼ˆ6 ä¸ªæœˆä»¥ä¸Šï¼‰

6. **æŒç»­ä¼˜åŒ–**
   - æ ¹æ®ç”Ÿäº§æ•°æ®ä¼˜åŒ–æŸ¥è¯¢åˆ†ç±»è§„åˆ™
   - ä¼˜åŒ–æ ‘æ„å»ºç®—æ³•ï¼ˆå‡å°‘ LLM è°ƒç”¨ï¼‰
   - æ¢ç´¢æ›´å…ˆè¿›çš„æ–¹æ³•ï¼ˆGraphRAGã€Hybrid RAGï¼‰

7. **åº”ç”¨æ¨å¹¿**
   - å°† Tree-based æ–¹æ³•åº”ç”¨åˆ°æ›´å¤šåœºæ™¯
   - æ²‰æ·€æœ€ä½³å®è·µå’Œå·¥å…·åº“

### ä¸å»ºè®®çš„åšæ³• âŒ

1. **å®Œå…¨æ›¿æ¢å‘é‡æ£€ç´¢**: æˆæœ¬é«˜ã€é£é™©å¤§ã€æ”¶ç›Šä¸æ˜ç¡®
2. **ä¸€æ­¥åˆ°ä½å®ç°å¤æ‚æ–¹æ¡ˆ**: ä¼˜å…ˆ MVPï¼Œå¿«é€ŸéªŒè¯
3. **å¿½ç•¥æˆæœ¬æ§åˆ¶**: å¿…é¡»è®¾å®šé¢„ç®—ä¸Šé™å¹¶ç›‘æ§
4. **ç¼ºä¹ A/B æµ‹è¯•**: ä¸»è§‚è¯„ä¼°ä¸å¯é ï¼Œå¿…é¡»åŸºäºæ•°æ®å†³ç­–

---

## 8. å‚è€ƒèµ„æ–™

### æ ¸å¿ƒè®ºæ–‡

1. **RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval**
   - è®ºæ–‡é“¾æ¥: [arxiv.org](https://arxiv.org/abs/2401.18059)
   - æ ¸å¿ƒè´¡çŒ®: æå‡ºé€’å½’æ‘˜è¦æ ‘æ„å»ºæ–¹æ³•

2. **Hierarchical RAG: A Survey**
   - æ¥æº: [emergentmind.com](https://emergentmind.com)
   - æ€»ç»“äº†å„ç±»å±‚æ¬¡åŒ– RAG æ–¹æ³•

### å¼€æºå®ç°

3. **å®˜æ–¹ RAPTOR å®ç°** (Python)
   - GitHub: [parthsarthi03/raptor](https://github.com/parthsarthi03/raptor)
   - Star: 2.8k+

4. **LangChain RAG æŠ€æœ¯é›†åˆ**
   - GitHub: [NirDiamant/RAG_Techniques](https://github.com/NirDiamant/RAG_Techniques)
   - åŒ…å«å¤šç§ RAG æ–¹æ³•çš„ Jupyter Notebook

### æŠ€æœ¯åšå®¢

5. **Optimizing RAG with RAPTOR Pipeline**
   - æ¥æº: [gitconnected.com](https://gitconnected.com)
   - è¯¦ç»†çš„å®ç°æ•™ç¨‹

6. **GraphRAG vs Vector RAG Comparison**
   - æ¥æº: [falkordb.com](https://falkordb.com)
   - æ€§èƒ½åŸºå‡†æµ‹è¯•å¯¹æ¯”

### Go è¯­è¨€åº“

7. **muesli/clusters** - KMeans èšç±»
   - GitHub: [github.com/muesli/clusters](https://github.com/muesli/clusters)

8. **gonum** - ç§‘å­¦è®¡ç®—
   - å®˜ç½‘: [gonum.org](https://gonum.org)

---

## é™„å½• A: æœ¯è¯­è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|------|------|------|
| **RAPTOR** | Recursive Abstractive Processing for Tree-Organized Retrieval | é€’å½’æ‘˜è¦æ ‘ç»„ç»‡æ£€ç´¢æ–¹æ³• |
| **HyDE** | Hypothetical Document Embeddings | å‡è®¾æ–‡æ¡£åµŒå…¥ï¼ˆç”Ÿæˆå‡è®¾ç­”æ¡ˆå¹¶åµŒå…¥ï¼‰ |
| **GMM** | Gaussian Mixture Models | é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆè½¯èšç±»ç®—æ³•ï¼‰ |
| **Tree Traversal** | - | æ ‘éå†ï¼ˆè‡ªé¡¶å‘ä¸‹æ£€ç´¢ç­–ç•¥ï¼‰ |
| **Collapsed Tree** | - | æ‰å¹³åŒ–æ ‘ï¼ˆè·¨å±‚ç›´æ¥æ£€ç´¢ï¼‰ |
| **Chunk** | - | æ–‡æ¡£åˆ†å—ï¼ˆé€šå¸¸ 100-1000 tokensï¼‰ |
| **Reranking** | - | é‡æ’åºï¼ˆä½¿ç”¨æ›´ç²¾ç»†æ¨¡å‹é‡æ–°æ’åºæ£€ç´¢ç»“æœï¼‰ |
| **GraphRAG** | Graph-based RAG | åŸºäºçŸ¥è¯†å›¾è°±çš„ RAG |

---

## é™„å½• B: å¿«é€Ÿå†³ç­–æµç¨‹å›¾

```
å¼€å§‹
  |
  â”œâ”€ æ˜¯å¦æœ‰é•¿æ–‡æ¡£ç†è§£éœ€æ±‚ï¼Ÿ
  |   â”œâ”€ æ˜¯ â†’ è€ƒè™‘ Tree-based
  |   â””â”€ å¦ â†’ ä¿æŒå‘é‡æ£€ç´¢
  |
  â”œâ”€ æ˜¯å¦æœ‰å¤æ‚æ¨ç†æŸ¥è¯¢ï¼Ÿ
  |   â”œâ”€ æ˜¯ â†’ è€ƒè™‘ Tree-based
  |   â””â”€ å¦ â†’ ä¿æŒå‘é‡æ£€ç´¢
  |
  â”œâ”€ æ˜¯å¦èƒ½æ¥å— 10x æ„å»ºæˆæœ¬ï¼Ÿ
  |   â”œâ”€ æ˜¯ â†’ å¯åŠ¨ POC
  |   â””â”€ å¦ â†’ æš‚ä¸å®æ–½
  |
  â”œâ”€ POC å‡†ç¡®ç‡æå‡ > 15%ï¼Ÿ
  |   â”œâ”€ æ˜¯ â†’ è¿›å…¥ç”Ÿäº§å®ç°
  |   â””â”€ å¦ â†’ ä¼˜åŒ–æˆ–æ”¾å¼ƒ
  |
ç»“æŸ
```

---

**è°ƒç ”å®Œæˆæ—¶é—´**: 2026-01-24
**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: ç­‰å¾…å†³ç­–æ˜¯å¦å¯åŠ¨ POC é¡¹ç›®
